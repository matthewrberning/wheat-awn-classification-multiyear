{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "expired-pierce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#matthew berning, 2021\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "\n",
    "import PIL\n",
    "import pandas as pd\n",
    "from tqdm import tqdm, trange\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "direct-recruitment",
   "metadata": {},
   "source": [
    "# Dataset Structure  \n",
    "  \n",
    "## We are interested in how the classifier performs over sucessive seasons -we have 2 to work with: 2019 and 2020  \n",
    "  \n",
    "so, we will train our model on 2019 data (train/test sets) and then evaluate on 2019 data and 2020 data (validation sets)\n",
    "\n",
    "## Awned cultivars outnumber awnless cultivars considerably..\n",
    "\n",
    "so, we need to over-sample the under represented class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "legal-green",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pless_nfs/home/matthewrberning/miniconda3/envs/data_exp38/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3165: DtypeWarning: Columns (7) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>plot_id</th>\n",
       "      <th>plot_name</th>\n",
       "      <th>yday</th>\n",
       "      <th>date</th>\n",
       "      <th>dir</th>\n",
       "      <th>file</th>\n",
       "      <th>PCTHEAD</th>\n",
       "      <th>AWNS</th>\n",
       "      <th>GRWT</th>\n",
       "      <th>GRYLD</th>\n",
       "      <th>LOI</th>\n",
       "      <th>MOIST</th>\n",
       "      <th>PTHT</th>\n",
       "      <th>SPKLNG</th>\n",
       "      <th>SPLSPK</th>\n",
       "      <th>SPNAREA</th>\n",
       "      <th>TESTWT</th>\n",
       "      <th>TGW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18ASH3-F-0100</td>\n",
       "      <td>EVEREST</td>\n",
       "      <td>128</td>\n",
       "      <td>2018-05-08</td>\n",
       "      <td>20180508_18ASH_AM3_X5R_6m_-60_video</td>\n",
       "      <td>DJI_A01733_C002_20180508_000123_1264_0824_1775...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AWNED</td>\n",
       "      <td>1216.0</td>\n",
       "      <td>2.68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.7</td>\n",
       "      <td>67.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18ASH3-F-0100</td>\n",
       "      <td>EVEREST</td>\n",
       "      <td>128</td>\n",
       "      <td>2018-05-08</td>\n",
       "      <td>20180508_18ASH_AM3_X5R_6m_-60_video</td>\n",
       "      <td>DJI_A01733_C002_20180508_000124_1776_0824_2287...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AWNED</td>\n",
       "      <td>1216.0</td>\n",
       "      <td>2.68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.7</td>\n",
       "      <td>67.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18ASH3-F-0100</td>\n",
       "      <td>EVEREST</td>\n",
       "      <td>128</td>\n",
       "      <td>2018-05-08</td>\n",
       "      <td>20180508_18ASH_AM3_X5R_6m_-60_video</td>\n",
       "      <td>DJI_A01733_C002_20180508_000123_2800_0824_3311...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AWNED</td>\n",
       "      <td>1216.0</td>\n",
       "      <td>2.68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.7</td>\n",
       "      <td>67.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18ASH3-F-0100</td>\n",
       "      <td>EVEREST</td>\n",
       "      <td>128</td>\n",
       "      <td>2018-05-08</td>\n",
       "      <td>20180508_18ASH_AM3_X5R_6m_-60_video</td>\n",
       "      <td>DJI_A01733_C002_20180508_000124_0240_0824_0751...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AWNED</td>\n",
       "      <td>1216.0</td>\n",
       "      <td>2.68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.7</td>\n",
       "      <td>67.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18ASH3-F-0100</td>\n",
       "      <td>EVEREST</td>\n",
       "      <td>128</td>\n",
       "      <td>2018-05-08</td>\n",
       "      <td>20180508_18ASH_AM3_X5R_6m_-60_video</td>\n",
       "      <td>DJI_A01733_C002_20180508_000121_2800_0824_3311...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AWNED</td>\n",
       "      <td>1216.0</td>\n",
       "      <td>2.68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.7</td>\n",
       "      <td>67.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         plot_id plot_name  yday        date  \\\n",
       "0  18ASH3-F-0100   EVEREST   128  2018-05-08   \n",
       "1  18ASH3-F-0100   EVEREST   128  2018-05-08   \n",
       "2  18ASH3-F-0100   EVEREST   128  2018-05-08   \n",
       "3  18ASH3-F-0100   EVEREST   128  2018-05-08   \n",
       "4  18ASH3-F-0100   EVEREST   128  2018-05-08   \n",
       "\n",
       "                                   dir  \\\n",
       "0  20180508_18ASH_AM3_X5R_6m_-60_video   \n",
       "1  20180508_18ASH_AM3_X5R_6m_-60_video   \n",
       "2  20180508_18ASH_AM3_X5R_6m_-60_video   \n",
       "3  20180508_18ASH_AM3_X5R_6m_-60_video   \n",
       "4  20180508_18ASH_AM3_X5R_6m_-60_video   \n",
       "\n",
       "                                                file  PCTHEAD   AWNS    GRWT  \\\n",
       "0  DJI_A01733_C002_20180508_000123_1264_0824_1775...      NaN  AWNED  1216.0   \n",
       "1  DJI_A01733_C002_20180508_000124_1776_0824_2287...      NaN  AWNED  1216.0   \n",
       "2  DJI_A01733_C002_20180508_000123_2800_0824_3311...      NaN  AWNED  1216.0   \n",
       "3  DJI_A01733_C002_20180508_000124_0240_0824_0751...      NaN  AWNED  1216.0   \n",
       "4  DJI_A01733_C002_20180508_000121_2800_0824_3311...      NaN  AWNED  1216.0   \n",
       "\n",
       "   GRYLD  LOI  MOIST  PTHT  SPKLNG  SPLSPK  SPNAREA  TESTWT  TGW  \n",
       "0   2.68  NaN   14.7  67.5     NaN     NaN      NaN    71.2  NaN  \n",
       "1   2.68  NaN   14.7  67.5     NaN     NaN      NaN    71.2  NaN  \n",
       "2   2.68  NaN   14.7  67.5     NaN     NaN      NaN    71.2  NaN  \n",
       "3   2.68  NaN   14.7  67.5     NaN     NaN      NaN    71.2  NaN  \n",
       "4   2.68  NaN   14.7  67.5     NaN     NaN      NaN    71.2  NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the 'key file' is our master dataset-structure document, it has all the file names and the respective info\n",
    "key_file = pd.read_csv(\"/pless_nfs/home/matthewrberning/multi-year-cult-class/data/KEY_AM-PANEL_20210414.csv\")\n",
    "\n",
    "#plot_name == cultivar\n",
    "#plot_id == unique plot number\n",
    "\n",
    "key_file.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coated-conservation",
   "metadata": {},
   "source": [
    "### the original data (.tif files) from KSU is located inside the Globus depository\n",
    "\n",
    "data_path: \"/pless_nfs/home/matthewrberning/globus/data/KSU/images_2021_02_01/images/X5R/processed/\"\n",
    "\n",
    "we can see when we list/sort/count the dirs that there are collection events for 2018, 2019, and 2020 data\n",
    "\n",
    "we can also see that there are more collection events for 2018 and 2019 then there are for 2020\n",
    "\n",
    "\n",
    "### during the initial cultivar classification project setup the 2019 and 2020 .tif images (512x512x4) were saved as center-cropped .jpg (300x300x3)\n",
    "\n",
    "data_path: \"/pless_nfs/home/matthewrberning/multi-year-cult-class/data/preprocessed/\"\n",
    "\n",
    "this was done to increase I/O speeds while still saving some space for data augmentation (the model expects 224x224x3)\n",
    "\n",
    "but, for safety's sake we should still validate that the data is where we think it is\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "pacific-cabin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20180508_18ASH_AM3_X5R_6m_-60_video',\n",
       " '20180510_18ASH_AM3_X5R_6m_-60_video',\n",
       " '20180514_18ASH_AM3_X5R_6m_-60_video',\n",
       " '20180515_18ASH_AM3_X5R_6m_-60_video',\n",
       " '20180516_18ASH_AM3_X5R_6m_-60_video',\n",
       " '20180517_18ASH_AM3_X5R_6m_-60_video',\n",
       " '20180518_18ASH_AM3_X5R_6m_-60_video',\n",
       " '20180521_18ASH_AM3_X5R_6m_-60_video',\n",
       " '20180522_18ASH_AM3_X5R_6m_-60_video',\n",
       " '20180523_18ASH_AM3_X5R_6m_-60_video',\n",
       " '20180525_18ASH_AM3_X5R_6m_-60_video',\n",
       " '20180528_18ASH_AM3_X5R_3m_-60_video',\n",
       " '20180529_18ASH_AM3_X5R_4m_-60_video',\n",
       " '20180531_18ASH_AM3_X5R_4m_-70_video',\n",
       " '20180601_18ASH_AM3_X5R_4m_-70_video',\n",
       " '20180613_18ASH_AM3_X5R_5m_-70_video',\n",
       " '20190506_19RF_AM_X5R_5m_-60_video_Flight1',\n",
       " '20190508_19RF_AM_X5R_5m_-60_video_Flight1',\n",
       " '20190510_19RF_AM_X5R_5m_-60_video_Flight1',\n",
       " '20190512_19RF_AM_X5R_5m_-60_video_Flight1',\n",
       " '20190513_19RF_AM_X5R_5m_-60_video_Flight1',\n",
       " '20190515_19RF_AM_X5R_5m_-60_video_Flight1',\n",
       " '20190516_19RF_AM_X5R_5m_-60_video_Flight1',\n",
       " '20190517_19RF_AM_X5R_5m_-60_video_Flight1',\n",
       " '20190519_19RF_AM_X5R_5m_-60_video_Flight1',\n",
       " '20190522_19RF_AM_X5R_5m_-60_video_Flight1',\n",
       " '20190523_19RF_AM_X5R_5m_-60_video_Flight1',\n",
       " '20190527_19RF_AM_X5R_5m_-60_video_Flight1',\n",
       " '20190603_19RF_AM_X5R_5m_-60_video_Flight1',\n",
       " '20190605_19RF_AM_X5R_5m_-60_video_Flight1',\n",
       " '20190610_19RF_AM_X5R_5m_-60_video_Flight1',\n",
       " '20190611_19RF_AM_X5R_5m_-60_video_Flight1',\n",
       " '20200505_20ASH_AM_X5R_5m_-60_video_flight1',\n",
       " '20200508_20ASH_AM_X5R_5m_-60_video_flight2',\n",
       " '20200511_20ASH_AM_X5R_5m_-60_video_flight2',\n",
       " '20200513_20ASH_AM_X5R_5m_-60_video_flight2',\n",
       " '20200515_20ASH_AM_X5R_5m_-60_video_flight2',\n",
       " '20200518_20ASH_AM_X5R_5m_-60_video_flight1',\n",
       " '20200520_20ASH_AM_X5R_5m_-60_video_flight1',\n",
       " '20200523_20ASH_AM_X5R_5m_-60_video_flight1',\n",
       " '20200527_20ASH_AM_X5R_5m_-60_video_flight1',\n",
       " '20200529_20ASH_AM_X5R_5m_-60_video_flight2',\n",
       " '20200603_20ASH_AM_X5R_5m_-90_video_flight1',\n",
       " '20200609_20ASH_AM_X5R_5m_-60_video_flight1']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"/pless_nfs/home/matthewrberning/globus/data/KSU/images_2021_02_01/images/X5R/processed/\"\n",
    "dir_lst = os.listdir(data_path)\n",
    "dir_lst.sort()\n",
    "\n",
    "#view the dirs\n",
    "dir_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "early-disposal",
   "metadata": {},
   "source": [
    "### (we're working with just 2019 and 2020 for now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "alive-vienna",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019 flights:  16\n",
      "2020 flights:  12\n"
     ]
    }
   ],
   "source": [
    "# empty lists to collect 2019/2020 \n",
    "lst_2019_dirs = []\n",
    "lst_2020_dirs = []\n",
    "\n",
    "# for each directory\n",
    "for d in dir_lst:\n",
    "    # check if the directory is from 2019\n",
    "    if '2019' in d:\n",
    "        #assemble list of 2019 dirs for training set\n",
    "        lst_2019_dirs.append(d)\n",
    "    \n",
    "    # check if it is from 2020\n",
    "    elif '2020' in d:\n",
    "        # assemble list of 2020 dirs for test set\n",
    "        lst_2020_dirs.append(d)\n",
    "\n",
    "\n",
    "print(\"2019 flights: \",len(lst_2019_dirs))       \n",
    "print(\"2020 flights: \",len(lst_2020_dirs))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "threaded-isaac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018 | images:   55783   dir: 20180508_18ASH_AM3_X5R_6m_-60_video\n",
      "2018 | images:   27230   dir: 20180510_18ASH_AM3_X5R_6m_-60_video\n",
      "2018 | images:   60368   dir: 20180514_18ASH_AM3_X5R_6m_-60_video\n",
      "2018 | images:   60326   dir: 20180515_18ASH_AM3_X5R_6m_-60_video\n",
      "2018 | images:   97461   dir: 20180516_18ASH_AM3_X5R_6m_-60_video\n",
      "2018 | images:   55503   dir: 20180517_18ASH_AM3_X5R_6m_-60_video\n",
      "2018 | images:   60368   dir: 20180518_18ASH_AM3_X5R_6m_-60_video\n",
      "2018 | images:   50512   dir: 20180521_18ASH_AM3_X5R_6m_-60_video\n",
      "2018 | images:   56861   dir: 20180522_18ASH_AM3_X5R_6m_-60_video\n",
      "2018 | images:   88319   dir: 20180523_18ASH_AM3_X5R_6m_-60_video\n",
      "2018 | images:   55258   dir: 20180525_18ASH_AM3_X5R_6m_-60_video\n",
      "2018 | images:   66682   dir: 20180528_18ASH_AM3_X5R_3m_-60_video\n",
      "2018 | images:   32116   dir: 20180529_18ASH_AM3_X5R_4m_-60_video\n",
      "2018 | images:  106197   dir: 20180531_18ASH_AM3_X5R_4m_-70_video\n",
      "2018 | images:   64596   dir: 20180601_18ASH_AM3_X5R_4m_-70_video\n",
      "2018 | images:  112077   dir: 20180613_18ASH_AM3_X5R_5m_-70_video\n",
      "-       TOTAL: 1049657   dirs: 16 [ average: 65604 ]\n",
      "2019 | images:   78239   dir: 20190506_19RF_AM_X5R_5m_-60_video_Flight1\n",
      "2019 | images:  102494   dir: 20190508_19RF_AM_X5R_5m_-60_video_Flight1\n",
      "2019 | images:   94185   dir: 20190510_19RF_AM_X5R_5m_-60_video_Flight1\n",
      "2019 | images:  102669   dir: 20190512_19RF_AM_X5R_5m_-60_video_Flight1\n",
      "2019 | images:  105924   dir: 20190513_19RF_AM_X5R_5m_-60_video_Flight1\n",
      "2019 | images:  107163   dir: 20190515_19RF_AM_X5R_5m_-60_video_Flight1\n",
      "2019 | images:   96859   dir: 20190516_19RF_AM_X5R_5m_-60_video_Flight1\n",
      "2019 | images:   73364   dir: 20190517_19RF_AM_X5R_5m_-60_video_Flight1\n",
      "2019 | images:   68238   dir: 20190519_19RF_AM_X5R_5m_-60_video_Flight1\n",
      "2019 | images:   67410   dir: 20190522_19RF_AM_X5R_5m_-60_video_Flight1\n",
      "2019 | images:   76363   dir: 20190523_19RF_AM_X5R_5m_-60_video_Flight1\n",
      "2019 | images:   90111   dir: 20190527_19RF_AM_X5R_5m_-60_video_Flight1\n",
      "2019 | images:   98035   dir: 20190603_19RF_AM_X5R_5m_-60_video_Flight1\n",
      "2019 | images:   99449   dir: 20190605_19RF_AM_X5R_5m_-60_video_Flight1\n",
      "2019 | images:   96257   dir: 20190610_19RF_AM_X5R_5m_-60_video_Flight1\n",
      "2019 | images:  115962   dir: 20190611_19RF_AM_X5R_5m_-60_video_Flight1\n",
      "-       TOTAL: 1472722   dirs: 16 [ average: 92046 ]\n",
      "2020 | images:   74599   dir: 20200505_20ASH_AM_X5R_5m_-60_video_flight1\n",
      "2020 | images:   73892   dir: 20200508_20ASH_AM_X5R_5m_-60_video_flight2\n",
      "2020 | images:   74725   dir: 20200511_20ASH_AM_X5R_5m_-60_video_flight2\n",
      "2020 | images:   75285   dir: 20200513_20ASH_AM_X5R_5m_-60_video_flight2\n",
      "2020 | images:   78946   dir: 20200515_20ASH_AM_X5R_5m_-60_video_flight2\n",
      "2020 | images:   81592   dir: 20200518_20ASH_AM_X5R_5m_-60_video_flight1\n",
      "2020 | images:   82012   dir: 20200520_20ASH_AM_X5R_5m_-60_video_flight1\n",
      "2020 | images:   70826   dir: 20200523_20ASH_AM_X5R_5m_-60_video_flight1\n",
      "2020 | images:   66465   dir: 20200527_20ASH_AM_X5R_5m_-60_video_flight1\n",
      "2020 | images:   63980   dir: 20200529_20ASH_AM_X5R_5m_-60_video_flight2\n",
      "2020 | images:   68355   dir: 20200603_20ASH_AM_X5R_5m_-90_video_flight1\n",
      "2020 | images:   77042   dir: 20200609_20ASH_AM_X5R_5m_-60_video_flight1\n",
      "-       TOTAL:  887719   dirs: 12 [ average: 73977 ]\n"
     ]
    }
   ],
   "source": [
    "#count and display the number of images in each directory\n",
    "previous_year = 2018 #var to help seperate out years\n",
    "\n",
    "year_count = 0 #var to track total images in a year\n",
    "\n",
    "dir_count = 0\n",
    "\n",
    "for d in dir_lst:\n",
    "    \n",
    "    #var to track the number of images\n",
    "    count = 0 \n",
    "    \n",
    "    #var to print the year\n",
    "    if '2018' in d:\n",
    "        year = 2018\n",
    "    elif '2019' in d:\n",
    "        year = 2019\n",
    "    else:\n",
    "        year = 2020\n",
    "        \n",
    "    #loop through list of objects inside the specified directory\n",
    "    for obj in os.listdir(os.path.join(data_path, d)):\n",
    "\n",
    "        #if it's a tif add to count\n",
    "        if obj.endswith('.tif'):\n",
    "            count+=1\n",
    "            \n",
    "    #align numbers for sanity\n",
    "    count = str(count).rjust(7)\n",
    "    \n",
    "    #seperate out years\n",
    "    if year != previous_year:\n",
    "        #report the total and average\n",
    "        print(f\"-       TOTAL: {str(year_count).rjust(7)}   dirs: {dir_count} [ average: {math.ceil(year_count/dir_count)} ]\")\n",
    "        year_count = 0 #reset the year count\n",
    "        \n",
    "        dir_count = 0 #reset the dir count\n",
    "    \n",
    "    #reset the current previous year\n",
    "    previous_year = year\n",
    "    \n",
    "    print(f\"{year} | images: {count}   dir: {d}\")\n",
    "    \n",
    "    #add the count for that dir to the total for the year\n",
    "    year_count+=int(count)\n",
    "    \n",
    "    #add to the count of directories for that year\n",
    "    dir_count+=1\n",
    "\n",
    "#report\n",
    "print(f\"-       TOTAL: {str(year_count).rjust(7)}   dirs: {dir_count} [ average: {math.ceil(year_count/dir_count)} ]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocal-channels",
   "metadata": {},
   "source": [
    "### now we'll isolate the image file names from 2019 and 2020 in the three places they're located\n",
    "1 - the key file  \n",
    "2 - the globus depository (.tif)  \n",
    "3 - the dir with cropped images (.jpg)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "structured-complaint",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2227833  image file names found\n",
      "example:  20190522_19RF_AM_X5R_5m_-60_video_Flight1_DJI_A00417_C024_20190522_000319_3312_0824_3823_1336_19RKY00116.jpg\n"
     ]
    }
   ],
   "source": [
    "#path to cropped data\n",
    "data_path = \"/pless_nfs/home/matthewrberning/multi-year-cult-class/data/preprocessed/\"\n",
    "\n",
    "#collect all the file names if they are images (end in .jpg)\n",
    "cropped_filenames_list = []\n",
    "\n",
    "path_lst = os.listdir(data_path)\n",
    "\n",
    "for obj in path_lst:\n",
    "    \n",
    "    #check if it's the image type we're looking for\n",
    "    if obj.endswith(\".jpg\"):\n",
    "        cropped_filenames_list.append(obj)\n",
    "        \n",
    "print(len(cropped_filenames_list), \" image file names found\")        \n",
    "print(\"example: \", cropped_filenames_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fluid-hayes",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00, 12.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2360441  image file names (plus dir name) found\n",
      "example:  20190506_19RF_AM_X5R_5m_-60_video_Flight1_DJI_A06276_C005_20190506_000722_1776_0824_2287_1336_19RKY00623.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#path to globus data\n",
    "data_path = \"/pless_nfs/home/matthewrberning/globus/data/KSU/images_2021_02_01/images/X5R/processed/\"\n",
    "\n",
    "#use previously found 2019 and 2020 dir names (lst_2019_dirs and lst_2020_dirs)\n",
    "list_of_dirs = lst_2019_dirs + lst_2020_dirs\n",
    "\n",
    "#empty list for collecting image paths\n",
    "tif_filenames_list = []\n",
    "\n",
    "\n",
    "#loop through list of dirs\n",
    "for _dir in tqdm(list_of_dirs):\n",
    "\n",
    "    #loop through list of objects inside the specified directory\n",
    "    for obj in os.listdir(os.path.join(data_path, _dir)):\n",
    "\n",
    "        #it's probably an image, add it to the list\n",
    "        if obj.endswith('.tif'):\n",
    "            \n",
    "            #modify the filename to match those in jpg dir for easier comparison\n",
    "            tif_filenames_list.append(f\"{_dir}_{obj}\")\n",
    "\n",
    "print(len(tif_filenames_list), \" image file names (plus dir name) found\")        \n",
    "print(\"example: \", tif_filenames_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "historical-collection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3410105  total image filenames\n",
      "2360448  image file names (plus dir name) gotten from key_file\n",
      "example:  20190506_19RF_AM_X5R_5m_-60_video_Flight1_DJI_A06276_C028_20190506_000040_1776_0824_2287_1336_19RKY0-F-0100.tif\n"
     ]
    }
   ],
   "source": [
    "#collect from the key_file\n",
    "key_file_filenames_list = []\n",
    "\n",
    "#copy the relevant data into a new df to collect from the key_file\n",
    "#(remember this doesn't work with mutable objects in a df)\n",
    "key_file_filenames_df = key_file[['dir', 'file']].copy(deep=True) \n",
    "\n",
    "#create a funt to combine path info into the dataframe too \n",
    "def create_filename(row, path):\n",
    "    \n",
    "    #concat the info in the rows\n",
    "    filename = row['dir'] + '_' + row['file']\n",
    "\n",
    "    return filename\n",
    "\n",
    "#apply the above helper function with lambda (expect a 'SettingWithCopyWarning')\n",
    "key_file_filenames_df['img_loc'] = key_file_filenames_df.apply (lambda row: create_filename(row, path), axis=1)\n",
    "\n",
    "#turn the whole collumn (2018, 2019, and 2020 names included) into a list\n",
    "key_file_filenames_lst_all = key_file_filenames_df['img_loc'].tolist()\n",
    "\n",
    "#get only 2019 and 2020 filenames\n",
    "for name in key_file_filenames_lst_all:\n",
    "    if '2019' in name or '2020' in name:\n",
    "#         if name.endswith(\".tif\")\n",
    "        key_file_filenames_list.append(name)\n",
    "\n",
    "print(len(key_file_filenames_lst_all), \" total image filenames (2018,2019, 2020)\")\n",
    "print(len(key_file_filenames_list), \" image file names (plus dir name) gotten from key_file (only 2019 and 2020)\")        \n",
    "print(\"example: \", key_file_filenames_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "damaged-cloud",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for files in key_file but not in the globus directory \n",
    "list(set(tif_filenames_list) - set(key_file_filenames_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "subsequent-terror",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20190517_19RF_AM_X5R_5m_-60_video_Flight1_DJI_A06276_C010_20190517_000962_2288_0824_2799_1336_19RKY00494.tif.filepart',\n",
       " '20190519_19RF_AM_X5R_5m_-60_video_Flight1_DJI_A06276_C001_20190519_000541_0240_0824_0751_1336_19RKY00715.tif.filepart',\n",
       " '20190519_19RF_AM_X5R_5m_-60_video_Flight1_DJI_A06276_C001_20190519_000540_2800_0824_3311_1336_19RKY00715.tif.filepart',\n",
       " '20190517_19RF_AM_X5R_5m_-60_video_Flight1_DJI_A06276_C016_20190517_000643_0240_0824_0751_1336_19RKY00329.tif.filepart',\n",
       " '20190519_19RF_AM_X5R_5m_-60_video_Flight1_DJI_A06276_C001_20190519_000540_2288_0824_2799_1336_19RKY00715.tif.filepart',\n",
       " '20190517_19RF_AM_X5R_5m_-60_video_Flight1_DJI_A06276_C016_20190517_000643_2288_0824_2799_1336_19RKY00329.tif.filepart',\n",
       " '20190519_19RF_AM_X5R_5m_-60_video_Flight1_DJI_A06276_C001_20190519_000541_1264_0824_1775_1336_19RKY00715.tif.filepart']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for files in globus directories but not in the key_file\n",
    "list(set(key_file_filenames_list) - set(tif_filenames_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worth-reach",
   "metadata": {},
   "source": [
    "### so.. we can see that there are some partial files created during the Globus transfer/download \n",
    "\n",
    "but all the files specified in the key file are present in the globus depository\n",
    "\n",
    "### the files in the cropped (.jpg) directory are all 2019 and 2020 images without 'fill plots' and NaN's\n",
    "we can verify this by first counting the total size of the 2019 and 2020 df's once the \n",
    "fill plots and NaN's have been removed, then we can also compare the filenames in the df's \n",
    "with the ones actually in the dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "organizational-policy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20190522_19RF_AM_X5R_5m_-60_video_Flight1_DJI_A00417_C024_20190522_000319_3312_0824_3823_1336_19RKY00116.jpg\n",
      "20190522_19RF_AM_X5R_5m_-60_video_Flight1_DJI_A00417_C024_20190522_000319_3312_0824_3823_1336_19RKY00116.tif\n",
      "\n",
      "file names in key_file but not in cropped directory:  132615\n"
     ]
    }
   ],
   "source": [
    "#rewrite the names of the files to end in '.tif' to make the comparison easier\n",
    "cropped_filenames_list_tiff = []\n",
    "\n",
    "for i in cropped_filenames_list:\n",
    "    cropped_filenames_list_tiff.append(i.split('.')[0] + '.tif')\n",
    "\n",
    "#verify change\n",
    "print(cropped_filenames_list[0])\n",
    "print(cropped_filenames_list_tiff[0])\n",
    "\n",
    "#check for files in key_file but not in the cropped directory (fill plots and Nan's)\n",
    "print(\"\\nfile names in key_file but not in cropped directory: \",len(list(set(key_file_filenames_list) - set(cropped_filenames_list_tiff))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "banner-psychiatry",
   "metadata": {},
   "source": [
    "### now we can look at the sizes of the dataset in terms of the key file\n",
    "we can also see how the cutlivars and awned vs awnless plots change "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "sought-procurement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3210556   -total entries in Key File WITHOUT FILL PLOTS\n",
      "3200182   -total entries in Key File WITHOUT FILL PLOTS and WITHOUT NaN's\n"
     ]
    }
   ],
   "source": [
    "#remove 'fill plots' i.e. plots just used for spacing out the relevant cultivars\n",
    "key_file_NoFillPlots = key_file[~key_file['plot_id'].str.contains('F')].copy(deep=True) \n",
    "print(len(key_file_NoFillPlots), \"  -total entries in Key File WITHOUT FILL PLOTS\")\n",
    "\n",
    "#remove plots where the cultivar was not reccorded (remember plot_name == cultivar)\n",
    "key_file_NoFillPlots_no_NaNs = key_file_NoFillPlots[key_file_NoFillPlots['plot_name'].notna()]\n",
    "print(len(key_file_NoFillPlots_no_NaNs),\"  -total entries in Key File WITHOUT FILL PLOTS and WITHOUT NaN's\")\n",
    "\n",
    "#examine the number of cultivars after each reduction\n",
    "# cultivars1 = key_file_NoFillPlots['plot_name'].unique()\n",
    "# print(f\"\\n{len(cultivars1)}  -Total CULTIVARS in Key File without Fill Plots\")\n",
    "\n",
    "# cultivars2 = key_file_NoFillPlots_no_NaNs['plot_name'].unique()\n",
    "# print(f\"{len(cultivars2)}  -Total CULTIVARS in Key File without Fill Plots and without NaN's\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imposed-foundation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#subdivide keyfile into dataframes for 2020 and 2019\n",
    "key_2020_data = key_file_NoFillPlots_no_NaNs[(key_file_NoFillPlots_no_NaNs['dir'].isin(lst_2020_dirs))]\n",
    "key_2019_data = key_file_NoFillPlots_no_NaNs[(key_file_NoFillPlots_no_NaNs['dir'].isin(lst_2019_dirs))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "alien-salvation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2227833  -total 2019 and 2020 data points\n",
      "1379769  -total 2019 data points (train/test)\n",
      " 848064  -total 2020 data points (validate)\n",
      "\n",
      "340  -Total CULTIVARS in key_2019_data\n",
      "340  -Total CULTIVARS in key_2020_data\n"
     ]
    }
   ],
   "source": [
    "print(f\"{str(len(key_2020_data) + len(key_2019_data)).rjust(7)}  -total 2019 and 2020 data points\") \n",
    "#note: the above num is the same as cropped_filename_list!\n",
    "\n",
    "print(f\"{str(len(key_2019_data)).rjust(7)}  -total 2019 data points (train/test)\")\n",
    "print(f\"{str(len(key_2020_data)).rjust(7)}  -total 2020 data points (validate)\")\n",
    "\n",
    "#determine how many cultivars are present in each dataset\n",
    "key_2020_data_cultivars =  key_2020_data['plot_name'].unique()\n",
    "key_2019_data_cultivars = key_2019_data['plot_name'].unique()\n",
    "\n",
    "print(f\"\\n{len(key_2019_data_cultivars)}  -Total CULTIVARS in key_2019_data\")\n",
    "print(f\"{len(key_2020_data_cultivars)}  -Total CULTIVARS in key_2020_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "injured-collection",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_filename_jpg(row, path):\n",
    "    \n",
    "    #concat the info in the rows\n",
    "    filename = row['dir'] + '_' + row['file'] + '.jpg'\n",
    "\n",
    "    return filename\n",
    "\n",
    "def compare_dir_with_df(dir_filenames_list, df1, df2):\n",
    "       \n",
    "    #collect the relevant columns from the dfs (copy so as to not mess with the originals)\n",
    "    filenames_df1 = df1[['dir', 'file']].copy(deep=True) \n",
    "    filenames_df2 = df2[['dir', 'file']].copy(deep=True) \n",
    "    \n",
    "    #use the helper function create_filename_jpg() as input to a lambda to make new columns \n",
    "    filenames_df1['img_loc'] = filenames_df1.apply (lambda row: create_filename_jpg(row, path), axis=1)\n",
    "    filenames_df2['img_loc'] = filenames_df2.apply (lambda row: create_filename_jpg(row, path), axis=1)\n",
    "    \n",
    "    #put the resultant columns into lists\n",
    "    df1_filenames_list = filenames_df1['img_loc'].tolist()\n",
    "    df2_filenames_list = filenames_df2['img_loc'].tolist()\n",
    "    \n",
    "    #add the two lists together\n",
    "    df_filenames_list = df1_filenames_list + df2_filenames_list\n",
    "    \n",
    "    #report output\n",
    "    print(f\"filenames in dir but not in df: {list(set(df_filenames_list) - set(dir_filenames_list))}\")\n",
    "    print(f\"filenames in df but not in dir: {list(set(dir_filenames_list) - set(df_filenames_list))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "international-reservation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare_dir_with_df(cropped_filenames_list, key_2020_data, key_2019_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "innovative-equality",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "filenames_df1 = key_2020_data[['dir', 'file']].copy(deep=True) \n",
    "filenames_df2 = key_2019_data[['dir', 'file']].copy(deep=True) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "sapphire-hormone",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the helper function create_filename_jpg() as input to a lambda to make new columns \n",
    "filenames_df1['img_loc'] = filenames_df1.apply (lambda row: create_filename_jpg(row, path), axis=1)\n",
    "filenames_df2['img_loc'] = filenames_df2.apply (lambda row: create_filename_jpg(row, path), axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "special-cursor",
   "metadata": {},
   "outputs": [],
   "source": [
    "#put the resultant columns into lists\n",
    "df1_filenames_list = filenames_df1['img_loc'].tolist()\n",
    "df2_filenames_list = filenames_df2['img_loc'].tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "reserved-firewall",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the two lists together\n",
    "df_filenames_list = df1_filenames_list + df2_filenames_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "orange-circular",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2227833"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_filenames_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "closing-desperate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2227833"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cropped_filenames_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "about-dominant",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"filenames in dir but not in df: {list(set(df_filenames_list) - set(cropped_filenames_list))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "short-tuition",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"filenames in df but not in dir: {list(set(cropped_filenames_list) - set(df_filenames_list))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expected-liver",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
