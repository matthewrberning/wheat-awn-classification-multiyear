{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "interesting-lesson",
   "metadata": {},
   "outputs": [],
   "source": [
    "#matthew berning, 2021\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import random\n",
    "\n",
    "import PIL\n",
    "import pandas as pd\n",
    "from tqdm import tqdm, trange\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excess-laugh",
   "metadata": {},
   "source": [
    "# Dataset Structure  \n",
    "  \n",
    "## We are interested in how the classifier performs over sucessive seasons -we have 2 to work with: 2019 and 2020  \n",
    "  \n",
    "so, we will train our model on 2019 data (train/test sets) and then evaluate on 2019 data and 2020 data (validation sets)\n",
    "\n",
    "## Awned cultivars outnumber awnless cultivars considerably..\n",
    "\n",
    "so, we need to over-sample the under represented class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "consecutive-tiger",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pless_nfs/home/matthewrberning/miniconda3/envs/data_exp38/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3165: DtypeWarning: Columns (7) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>plot_id</th>\n",
       "      <th>plot_name</th>\n",
       "      <th>yday</th>\n",
       "      <th>date</th>\n",
       "      <th>dir</th>\n",
       "      <th>file</th>\n",
       "      <th>PCTHEAD</th>\n",
       "      <th>AWNS</th>\n",
       "      <th>GRWT</th>\n",
       "      <th>GRYLD</th>\n",
       "      <th>LOI</th>\n",
       "      <th>MOIST</th>\n",
       "      <th>PTHT</th>\n",
       "      <th>SPKLNG</th>\n",
       "      <th>SPLSPK</th>\n",
       "      <th>SPNAREA</th>\n",
       "      <th>TESTWT</th>\n",
       "      <th>TGW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18ASH3-F-0100</td>\n",
       "      <td>EVEREST</td>\n",
       "      <td>128</td>\n",
       "      <td>2018-05-08</td>\n",
       "      <td>20180508_18ASH_AM3_X5R_6m_-60_video</td>\n",
       "      <td>DJI_A01733_C002_20180508_000123_1264_0824_1775...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AWNED</td>\n",
       "      <td>1216.0</td>\n",
       "      <td>2.68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.7</td>\n",
       "      <td>67.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18ASH3-F-0100</td>\n",
       "      <td>EVEREST</td>\n",
       "      <td>128</td>\n",
       "      <td>2018-05-08</td>\n",
       "      <td>20180508_18ASH_AM3_X5R_6m_-60_video</td>\n",
       "      <td>DJI_A01733_C002_20180508_000124_1776_0824_2287...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AWNED</td>\n",
       "      <td>1216.0</td>\n",
       "      <td>2.68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.7</td>\n",
       "      <td>67.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18ASH3-F-0100</td>\n",
       "      <td>EVEREST</td>\n",
       "      <td>128</td>\n",
       "      <td>2018-05-08</td>\n",
       "      <td>20180508_18ASH_AM3_X5R_6m_-60_video</td>\n",
       "      <td>DJI_A01733_C002_20180508_000123_2800_0824_3311...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AWNED</td>\n",
       "      <td>1216.0</td>\n",
       "      <td>2.68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.7</td>\n",
       "      <td>67.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18ASH3-F-0100</td>\n",
       "      <td>EVEREST</td>\n",
       "      <td>128</td>\n",
       "      <td>2018-05-08</td>\n",
       "      <td>20180508_18ASH_AM3_X5R_6m_-60_video</td>\n",
       "      <td>DJI_A01733_C002_20180508_000124_0240_0824_0751...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AWNED</td>\n",
       "      <td>1216.0</td>\n",
       "      <td>2.68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.7</td>\n",
       "      <td>67.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18ASH3-F-0100</td>\n",
       "      <td>EVEREST</td>\n",
       "      <td>128</td>\n",
       "      <td>2018-05-08</td>\n",
       "      <td>20180508_18ASH_AM3_X5R_6m_-60_video</td>\n",
       "      <td>DJI_A01733_C002_20180508_000121_2800_0824_3311...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AWNED</td>\n",
       "      <td>1216.0</td>\n",
       "      <td>2.68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.7</td>\n",
       "      <td>67.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         plot_id plot_name  yday        date  \\\n",
       "0  18ASH3-F-0100   EVEREST   128  2018-05-08   \n",
       "1  18ASH3-F-0100   EVEREST   128  2018-05-08   \n",
       "2  18ASH3-F-0100   EVEREST   128  2018-05-08   \n",
       "3  18ASH3-F-0100   EVEREST   128  2018-05-08   \n",
       "4  18ASH3-F-0100   EVEREST   128  2018-05-08   \n",
       "\n",
       "                                   dir  \\\n",
       "0  20180508_18ASH_AM3_X5R_6m_-60_video   \n",
       "1  20180508_18ASH_AM3_X5R_6m_-60_video   \n",
       "2  20180508_18ASH_AM3_X5R_6m_-60_video   \n",
       "3  20180508_18ASH_AM3_X5R_6m_-60_video   \n",
       "4  20180508_18ASH_AM3_X5R_6m_-60_video   \n",
       "\n",
       "                                                file  PCTHEAD   AWNS    GRWT  \\\n",
       "0  DJI_A01733_C002_20180508_000123_1264_0824_1775...      NaN  AWNED  1216.0   \n",
       "1  DJI_A01733_C002_20180508_000124_1776_0824_2287...      NaN  AWNED  1216.0   \n",
       "2  DJI_A01733_C002_20180508_000123_2800_0824_3311...      NaN  AWNED  1216.0   \n",
       "3  DJI_A01733_C002_20180508_000124_0240_0824_0751...      NaN  AWNED  1216.0   \n",
       "4  DJI_A01733_C002_20180508_000121_2800_0824_3311...      NaN  AWNED  1216.0   \n",
       "\n",
       "   GRYLD  LOI  MOIST  PTHT  SPKLNG  SPLSPK  SPNAREA  TESTWT  TGW  \n",
       "0   2.68  NaN   14.7  67.5     NaN     NaN      NaN    71.2  NaN  \n",
       "1   2.68  NaN   14.7  67.5     NaN     NaN      NaN    71.2  NaN  \n",
       "2   2.68  NaN   14.7  67.5     NaN     NaN      NaN    71.2  NaN  \n",
       "3   2.68  NaN   14.7  67.5     NaN     NaN      NaN    71.2  NaN  \n",
       "4   2.68  NaN   14.7  67.5     NaN     NaN      NaN    71.2  NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the 'key file' is our master dataset-structure document, it has all the file names and the respective info\n",
    "key_file = pd.read_csv(\"/pless_nfs/home/matthewrberning/multi-year-cult-class/data/KEY_AM-PANEL_20210414.csv\")\n",
    "\n",
    "#plot_name == cultivar\n",
    "#plot_id == unique plot number\n",
    "\n",
    "key_file.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "periodic-webcam",
   "metadata": {},
   "source": [
    "### the original data (.tif files) from KSU is located inside the Globus depository\n",
    "\n",
    "data_path: \"/pless_nfs/home/matthewrberning/globus/data/KSU/images_2021_02_01/images/X5R/processed/\"\n",
    "\n",
    "we can see when we list/sort/count the dirs that there are collection events for 2018, 2019, and 2020 data\n",
    "\n",
    "we can also see that there are more collection events for 2018 and 2019 then there are for 2020\n",
    "\n",
    "\n",
    "### during the initial cultivar classification project setup the 2019 and 2020 .tif images (512x512x4) were saved as center-cropped .jpg (300x300x3)\n",
    "\n",
    "data_path: \"/pless_nfs/home/matthewrberning/multi-year-cult-class/data/preprocessed/\"\n",
    "\n",
    "this was done to increase I/O speeds while still saving some space for data augmentation (the model expects 224x224x3)\n",
    "\n",
    "but, for safety's sake we should still validate that the data is where we think it is\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "hungarian-remove",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20180508_18ASH_AM3_X5R_6m_-60_video',\n",
       " '20180510_18ASH_AM3_X5R_6m_-60_video',\n",
       " '20180514_18ASH_AM3_X5R_6m_-60_video',\n",
       " '20180515_18ASH_AM3_X5R_6m_-60_video',\n",
       " '20180516_18ASH_AM3_X5R_6m_-60_video',\n",
       " '20180517_18ASH_AM3_X5R_6m_-60_video',\n",
       " '20180518_18ASH_AM3_X5R_6m_-60_video',\n",
       " '20180521_18ASH_AM3_X5R_6m_-60_video',\n",
       " '20180522_18ASH_AM3_X5R_6m_-60_video',\n",
       " '20180523_18ASH_AM3_X5R_6m_-60_video',\n",
       " '20180525_18ASH_AM3_X5R_6m_-60_video',\n",
       " '20180528_18ASH_AM3_X5R_3m_-60_video',\n",
       " '20180529_18ASH_AM3_X5R_4m_-60_video',\n",
       " '20180531_18ASH_AM3_X5R_4m_-70_video',\n",
       " '20180601_18ASH_AM3_X5R_4m_-70_video',\n",
       " '20180613_18ASH_AM3_X5R_5m_-70_video',\n",
       " '20190506_19RF_AM_X5R_5m_-60_video_Flight1',\n",
       " '20190508_19RF_AM_X5R_5m_-60_video_Flight1',\n",
       " '20190510_19RF_AM_X5R_5m_-60_video_Flight1',\n",
       " '20190512_19RF_AM_X5R_5m_-60_video_Flight1',\n",
       " '20190513_19RF_AM_X5R_5m_-60_video_Flight1',\n",
       " '20190515_19RF_AM_X5R_5m_-60_video_Flight1',\n",
       " '20190516_19RF_AM_X5R_5m_-60_video_Flight1',\n",
       " '20190517_19RF_AM_X5R_5m_-60_video_Flight1',\n",
       " '20190519_19RF_AM_X5R_5m_-60_video_Flight1',\n",
       " '20190522_19RF_AM_X5R_5m_-60_video_Flight1',\n",
       " '20190523_19RF_AM_X5R_5m_-60_video_Flight1',\n",
       " '20190527_19RF_AM_X5R_5m_-60_video_Flight1',\n",
       " '20190603_19RF_AM_X5R_5m_-60_video_Flight1',\n",
       " '20190605_19RF_AM_X5R_5m_-60_video_Flight1',\n",
       " '20190610_19RF_AM_X5R_5m_-60_video_Flight1',\n",
       " '20190611_19RF_AM_X5R_5m_-60_video_Flight1',\n",
       " '20200505_20ASH_AM_X5R_5m_-60_video_flight1',\n",
       " '20200508_20ASH_AM_X5R_5m_-60_video_flight2',\n",
       " '20200511_20ASH_AM_X5R_5m_-60_video_flight2',\n",
       " '20200513_20ASH_AM_X5R_5m_-60_video_flight2',\n",
       " '20200515_20ASH_AM_X5R_5m_-60_video_flight2',\n",
       " '20200518_20ASH_AM_X5R_5m_-60_video_flight1',\n",
       " '20200520_20ASH_AM_X5R_5m_-60_video_flight1',\n",
       " '20200523_20ASH_AM_X5R_5m_-60_video_flight1',\n",
       " '20200527_20ASH_AM_X5R_5m_-60_video_flight1',\n",
       " '20200529_20ASH_AM_X5R_5m_-60_video_flight2',\n",
       " '20200603_20ASH_AM_X5R_5m_-90_video_flight1',\n",
       " '20200609_20ASH_AM_X5R_5m_-60_video_flight1']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"/pless_nfs/home/matthewrberning/globus/data/KSU/images_2021_02_01/images/X5R/processed/\"\n",
    "dir_lst = os.listdir(data_path)\n",
    "dir_lst.sort()\n",
    "\n",
    "#view the dirs\n",
    "dir_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explicit-stamp",
   "metadata": {},
   "source": [
    "### (we're working with just 2019 and 2020 for now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "endangered-sullivan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019 flights:  16\n",
      "2020 flights:  12\n"
     ]
    }
   ],
   "source": [
    "# empty lists to collect 2019/2020 \n",
    "lst_2019_dirs = []\n",
    "lst_2020_dirs = []\n",
    "\n",
    "# for each directory\n",
    "for d in dir_lst:\n",
    "    # check if the directory is from 2019\n",
    "    if '2019' in d:\n",
    "        #assemble list of 2019 dirs for training set\n",
    "        lst_2019_dirs.append(d)\n",
    "    \n",
    "    # check if it is from 2020\n",
    "    elif '2020' in d:\n",
    "        # assemble list of 2020 dirs for test set\n",
    "        lst_2020_dirs.append(d)\n",
    "\n",
    "\n",
    "print(\"2019 flights: \",len(lst_2019_dirs))       \n",
    "print(\"2020 flights: \",len(lst_2020_dirs))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "spoken-authorization",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018 | images:   55783   dir: 20180508_18ASH_AM3_X5R_6m_-60_video\n",
      "2018 | images:   27230   dir: 20180510_18ASH_AM3_X5R_6m_-60_video\n",
      "2018 | images:   60368   dir: 20180514_18ASH_AM3_X5R_6m_-60_video\n",
      "2018 | images:   60326   dir: 20180515_18ASH_AM3_X5R_6m_-60_video\n",
      "2018 | images:   97461   dir: 20180516_18ASH_AM3_X5R_6m_-60_video\n",
      "2018 | images:   55503   dir: 20180517_18ASH_AM3_X5R_6m_-60_video\n",
      "2018 | images:   60368   dir: 20180518_18ASH_AM3_X5R_6m_-60_video\n",
      "2018 | images:   50512   dir: 20180521_18ASH_AM3_X5R_6m_-60_video\n",
      "2018 | images:   56861   dir: 20180522_18ASH_AM3_X5R_6m_-60_video\n",
      "2018 | images:   88319   dir: 20180523_18ASH_AM3_X5R_6m_-60_video\n",
      "2018 | images:   55258   dir: 20180525_18ASH_AM3_X5R_6m_-60_video\n",
      "2018 | images:   66682   dir: 20180528_18ASH_AM3_X5R_3m_-60_video\n",
      "2018 | images:   32116   dir: 20180529_18ASH_AM3_X5R_4m_-60_video\n",
      "2018 | images:  106197   dir: 20180531_18ASH_AM3_X5R_4m_-70_video\n",
      "2018 | images:   64596   dir: 20180601_18ASH_AM3_X5R_4m_-70_video\n",
      "2018 | images:  112077   dir: 20180613_18ASH_AM3_X5R_5m_-70_video\n",
      "-       TOTAL: 1049657   dirs: 16 [ average: 65604 ]\n",
      "2019 | images:   78239   dir: 20190506_19RF_AM_X5R_5m_-60_video_Flight1\n",
      "2019 | images:  102494   dir: 20190508_19RF_AM_X5R_5m_-60_video_Flight1\n",
      "2019 | images:   94185   dir: 20190510_19RF_AM_X5R_5m_-60_video_Flight1\n",
      "2019 | images:  102669   dir: 20190512_19RF_AM_X5R_5m_-60_video_Flight1\n",
      "2019 | images:  105924   dir: 20190513_19RF_AM_X5R_5m_-60_video_Flight1\n",
      "2019 | images:  107163   dir: 20190515_19RF_AM_X5R_5m_-60_video_Flight1\n",
      "2019 | images:   96859   dir: 20190516_19RF_AM_X5R_5m_-60_video_Flight1\n",
      "2019 | images:   73364   dir: 20190517_19RF_AM_X5R_5m_-60_video_Flight1\n",
      "2019 | images:   68238   dir: 20190519_19RF_AM_X5R_5m_-60_video_Flight1\n",
      "2019 | images:   67410   dir: 20190522_19RF_AM_X5R_5m_-60_video_Flight1\n",
      "2019 | images:   76363   dir: 20190523_19RF_AM_X5R_5m_-60_video_Flight1\n",
      "2019 | images:   90111   dir: 20190527_19RF_AM_X5R_5m_-60_video_Flight1\n",
      "2019 | images:   98035   dir: 20190603_19RF_AM_X5R_5m_-60_video_Flight1\n",
      "2019 | images:   99449   dir: 20190605_19RF_AM_X5R_5m_-60_video_Flight1\n",
      "2019 | images:   96257   dir: 20190610_19RF_AM_X5R_5m_-60_video_Flight1\n",
      "2019 | images:  115962   dir: 20190611_19RF_AM_X5R_5m_-60_video_Flight1\n",
      "-       TOTAL: 1472722   dirs: 16 [ average: 92046 ]\n",
      "2020 | images:   74599   dir: 20200505_20ASH_AM_X5R_5m_-60_video_flight1\n",
      "2020 | images:   73892   dir: 20200508_20ASH_AM_X5R_5m_-60_video_flight2\n",
      "2020 | images:   74725   dir: 20200511_20ASH_AM_X5R_5m_-60_video_flight2\n",
      "2020 | images:   75285   dir: 20200513_20ASH_AM_X5R_5m_-60_video_flight2\n",
      "2020 | images:   78946   dir: 20200515_20ASH_AM_X5R_5m_-60_video_flight2\n",
      "2020 | images:   81592   dir: 20200518_20ASH_AM_X5R_5m_-60_video_flight1\n",
      "2020 | images:   82012   dir: 20200520_20ASH_AM_X5R_5m_-60_video_flight1\n",
      "2020 | images:   70826   dir: 20200523_20ASH_AM_X5R_5m_-60_video_flight1\n",
      "2020 | images:   66465   dir: 20200527_20ASH_AM_X5R_5m_-60_video_flight1\n",
      "2020 | images:   63980   dir: 20200529_20ASH_AM_X5R_5m_-60_video_flight2\n",
      "2020 | images:   68355   dir: 20200603_20ASH_AM_X5R_5m_-90_video_flight1\n",
      "2020 | images:   77042   dir: 20200609_20ASH_AM_X5R_5m_-60_video_flight1\n",
      "-       TOTAL:  887719   dirs: 12 [ average: 73977 ]\n"
     ]
    }
   ],
   "source": [
    "#count and display the number of images in each directory\n",
    "previous_year = 2018 #var to help seperate out years\n",
    "\n",
    "year_count = 0 #var to track total images in a year\n",
    "\n",
    "dir_count = 0\n",
    "\n",
    "for d in dir_lst:\n",
    "    \n",
    "    #var to track the number of images\n",
    "    count = 0 \n",
    "    \n",
    "    #var to print the year\n",
    "    if '2018' in d:\n",
    "        year = 2018\n",
    "    elif '2019' in d:\n",
    "        year = 2019\n",
    "    else:\n",
    "        year = 2020\n",
    "        \n",
    "    #loop through list of objects inside the specified directory\n",
    "    for obj in os.listdir(os.path.join(data_path, d)):\n",
    "\n",
    "        #if it's a tif add to count\n",
    "        if obj.endswith('.tif'):\n",
    "            count+=1\n",
    "            \n",
    "    #align numbers for sanity\n",
    "    count = str(count).rjust(7)\n",
    "    \n",
    "    #seperate out years\n",
    "    if year != previous_year:\n",
    "        #report the total and average\n",
    "        print(f\"-       TOTAL: {str(year_count).rjust(7)}   dirs: {dir_count} [ average: {math.ceil(year_count/dir_count)} ]\")\n",
    "        year_count = 0 #reset the year count\n",
    "        \n",
    "        dir_count = 0 #reset the dir count\n",
    "    \n",
    "    #reset the current previous year\n",
    "    previous_year = year\n",
    "    \n",
    "    print(f\"{year} | images: {count}   dir: {d}\")\n",
    "    \n",
    "    #add the count for that dir to the total for the year\n",
    "    year_count+=int(count)\n",
    "    \n",
    "    #add to the count of directories for that year\n",
    "    dir_count+=1\n",
    "\n",
    "#report\n",
    "print(f\"-       TOTAL: {str(year_count).rjust(7)}   dirs: {dir_count} [ average: {math.ceil(year_count/dir_count)} ]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clean-purpose",
   "metadata": {},
   "source": [
    "### now we'll isolate the image file names from 2019 and 2020 in the three places they're located\n",
    "1 - the key file  \n",
    "2 - the globus depository (.tif)  \n",
    "3 - the dir with cropped images (.jpg)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "residential-enlargement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2227833  image file names found\n",
      "example:  20190522_19RF_AM_X5R_5m_-60_video_Flight1_DJI_A00417_C024_20190522_000319_3312_0824_3823_1336_19RKY00116.jpg\n"
     ]
    }
   ],
   "source": [
    "#path to cropped data\n",
    "data_path = \"/pless_nfs/home/matthewrberning/multi-year-cult-class/data/preprocessed/\"\n",
    "\n",
    "#collect all the file names if they are images (end in .jpg)\n",
    "cropped_filenames_list = []\n",
    "\n",
    "path_lst = os.listdir(data_path)\n",
    "\n",
    "for obj in path_lst:\n",
    "    \n",
    "    #check if it's the image type we're looking for\n",
    "    if obj.endswith(\".jpg\"):\n",
    "        cropped_filenames_list.append(obj)\n",
    "        \n",
    "print(len(cropped_filenames_list), \" image file names found\")        \n",
    "print(\"example: \", cropped_filenames_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "personalized-familiar",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00, 12.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2360441  image file names (plus dir name) found\n",
      "example:  20190506_19RF_AM_X5R_5m_-60_video_Flight1_DJI_A06276_C005_20190506_000722_1776_0824_2287_1336_19RKY00623.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#path to globus data\n",
    "data_path = \"/pless_nfs/home/matthewrberning/globus/data/KSU/images_2021_02_01/images/X5R/processed/\"\n",
    "\n",
    "#use previously found 2019 and 2020 dir names (lst_2019_dirs and lst_2020_dirs)\n",
    "list_of_dirs = lst_2019_dirs + lst_2020_dirs\n",
    "\n",
    "#empty list for collecting image paths\n",
    "tif_filenames_list = []\n",
    "\n",
    "\n",
    "#loop through list of dirs\n",
    "for _dir in tqdm(list_of_dirs):\n",
    "\n",
    "    #loop through list of objects inside the specified directory\n",
    "    for obj in os.listdir(os.path.join(data_path, _dir)):\n",
    "\n",
    "        #it's probably an image, add it to the list\n",
    "        if obj.endswith('.tif'):\n",
    "            \n",
    "            #modify the filename to match those in jpg dir for easier comparison\n",
    "            tif_filenames_list.append(f\"{_dir}_{obj}\")\n",
    "\n",
    "print(len(tif_filenames_list), \" image file names (plus dir name) found\")        \n",
    "print(\"example: \", tif_filenames_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "meaning-laser",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3410105  total image filenames\n",
      "2360448  image file names (plus dir name) gotten from key_file\n",
      "example:  20190506_19RF_AM_X5R_5m_-60_video_Flight1_DJI_A06276_C028_20190506_000040_1776_0824_2287_1336_19RKY0-F-0100.tif\n"
     ]
    }
   ],
   "source": [
    "#collect from the key_file\n",
    "key_file_filenames_list = []\n",
    "\n",
    "#copy the relevant data into a new df to collect from the key_file\n",
    "#(remember this doesn't work with mutable objects in a df)\n",
    "key_file_filenames_df = key_file[['dir', 'file']].copy(deep=True) \n",
    "\n",
    "#create a funt to combine path info into the dataframe too \n",
    "def create_filename(row, path):\n",
    "    \n",
    "    #concat the info in the rows\n",
    "    filename = row['dir'] + '_' + row['file']\n",
    "\n",
    "    return filename\n",
    "\n",
    "#apply the above helper function with lambda (expect a 'SettingWithCopyWarning')\n",
    "key_file_filenames_df['img_loc'] = key_file_filenames_df.apply (lambda row: create_filename(row, path), axis=1)\n",
    "\n",
    "#turn the whole collumn (2018, 2019, and 2020 names included) into a list\n",
    "key_file_filenames_lst_all = key_file_filenames_df['img_loc'].tolist()\n",
    "\n",
    "#get only 2019 and 2020 filenames\n",
    "for name in key_file_filenames_lst_all:\n",
    "    if '2019' in name or '2020' in name:\n",
    "#         if name.endswith(\".tif\")\n",
    "        key_file_filenames_list.append(name)\n",
    "\n",
    "print(len(key_file_filenames_lst_all), \" total image filenames (2018,2019, 2020)\")\n",
    "print(len(key_file_filenames_list), \" image file names (plus dir name) gotten from key_file (only 2019 and 2020)\")        \n",
    "print(\"example: \", key_file_filenames_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "reserved-integral",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for files in key_file but not in the globus directory \n",
    "list(set(tif_filenames_list) - set(key_file_filenames_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "attended-edinburgh",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20190517_19RF_AM_X5R_5m_-60_video_Flight1_DJI_A06276_C010_20190517_000962_2288_0824_2799_1336_19RKY00494.tif.filepart',\n",
       " '20190519_19RF_AM_X5R_5m_-60_video_Flight1_DJI_A06276_C001_20190519_000541_0240_0824_0751_1336_19RKY00715.tif.filepart',\n",
       " '20190519_19RF_AM_X5R_5m_-60_video_Flight1_DJI_A06276_C001_20190519_000540_2800_0824_3311_1336_19RKY00715.tif.filepart',\n",
       " '20190517_19RF_AM_X5R_5m_-60_video_Flight1_DJI_A06276_C016_20190517_000643_0240_0824_0751_1336_19RKY00329.tif.filepart',\n",
       " '20190519_19RF_AM_X5R_5m_-60_video_Flight1_DJI_A06276_C001_20190519_000540_2288_0824_2799_1336_19RKY00715.tif.filepart',\n",
       " '20190517_19RF_AM_X5R_5m_-60_video_Flight1_DJI_A06276_C016_20190517_000643_2288_0824_2799_1336_19RKY00329.tif.filepart',\n",
       " '20190519_19RF_AM_X5R_5m_-60_video_Flight1_DJI_A06276_C001_20190519_000541_1264_0824_1775_1336_19RKY00715.tif.filepart']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for files in globus directories but not in the key_file\n",
    "list(set(key_file_filenames_list) - set(tif_filenames_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "velvet-thanks",
   "metadata": {},
   "source": [
    "### so.. we can see that there are some partial files created during the Globus transfer/download \n",
    "\n",
    "but all the files specified in the key file are present in the globus depository\n",
    "\n",
    "### the files in the cropped (.jpg) directory are all 2019 and 2020 images without 'fill plots' and NaN's\n",
    "we can verify this by first counting the total size of the 2019 and 2020 df's once the \n",
    "fill plots and NaN's have been removed, then we can also compare the filenames in the df's \n",
    "with the ones actually in the dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "saved-albuquerque",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20190522_19RF_AM_X5R_5m_-60_video_Flight1_DJI_A00417_C024_20190522_000319_3312_0824_3823_1336_19RKY00116.jpg\n",
      "20190522_19RF_AM_X5R_5m_-60_video_Flight1_DJI_A00417_C024_20190522_000319_3312_0824_3823_1336_19RKY00116.tif\n",
      "\n",
      "file names in key_file but not in cropped directory:  132615\n"
     ]
    }
   ],
   "source": [
    "#rewrite the names of the files to end in '.tif' to make the comparison easier\n",
    "cropped_filenames_list_tiff = []\n",
    "\n",
    "for i in cropped_filenames_list:\n",
    "    cropped_filenames_list_tiff.append(i.split('.')[0] + '.tif')\n",
    "\n",
    "#verify change\n",
    "print(cropped_filenames_list[0])\n",
    "print(cropped_filenames_list_tiff[0])\n",
    "\n",
    "#check for files in key_file but not in the cropped directory (fill plots and Nan's)\n",
    "print(\"\\nfile names in key_file but not in cropped directory: \",len(list(set(key_file_filenames_list) - set(cropped_filenames_list_tiff))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seven-three",
   "metadata": {},
   "source": [
    "### now we can look at the sizes of the dataset in terms of the key file\n",
    "we can also see how the cutlivars and awned vs awnless plots change "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "loose-dance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3210556   -total entries in Key File WITHOUT FILL PLOTS\n",
      "3200182   -total entries in Key File WITHOUT FILL PLOTS and WITHOUT NaN's\n"
     ]
    }
   ],
   "source": [
    "#remove 'fill plots' i.e. plots just used for spacing out the relevant cultivars\n",
    "key_file_NoFillPlots = key_file[~key_file['plot_id'].str.contains('F')].copy(deep=True) \n",
    "print(len(key_file_NoFillPlots), \"  -total entries in Key File WITHOUT FILL PLOTS\")\n",
    "\n",
    "#remove plots where the cultivar was not reccorded (remember plot_name == cultivar)\n",
    "key_file_NoFillPlots_no_NaNs = key_file_NoFillPlots[key_file_NoFillPlots['plot_name'].notna()]\n",
    "print(len(key_file_NoFillPlots_no_NaNs),\"  -total entries in Key File WITHOUT FILL PLOTS and WITHOUT NaN's\")\n",
    "\n",
    "#examine the number of cultivars after each reduction\n",
    "# cultivars1 = key_file_NoFillPlots['plot_name'].unique()\n",
    "# print(f\"\\n{len(cultivars1)}  -Total CULTIVARS in Key File without Fill Plots\")\n",
    "\n",
    "# cultivars2 = key_file_NoFillPlots_no_NaNs['plot_name'].unique()\n",
    "# print(f\"{len(cultivars2)}  -Total CULTIVARS in Key File without Fill Plots and without NaN's\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "congressional-monitoring",
   "metadata": {},
   "outputs": [],
   "source": [
    "#subdivide keyfile into dataframes for 2020 and 2019\n",
    "key_2020_data = key_file_NoFillPlots_no_NaNs[(key_file_NoFillPlots_no_NaNs['dir'].isin(lst_2020_dirs))]\n",
    "key_2019_data = key_file_NoFillPlots_no_NaNs[(key_file_NoFillPlots_no_NaNs['dir'].isin(lst_2019_dirs))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "intensive-future",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2227833  -total 2019 and 2020 data points\n",
      "1379769  -total 2019 data points (train/test)\n",
      " 848064  -total 2020 data points (validate)\n",
      "\n",
      "340  -Total CULTIVARS in key_2019_data\n",
      "340  -Total CULTIVARS in key_2020_data\n"
     ]
    }
   ],
   "source": [
    "print(f\"{str(len(key_2020_data) + len(key_2019_data)).rjust(7)}  -total 2019 and 2020 data points\") \n",
    "#note: the above num is the same as cropped_filename_list!\n",
    "\n",
    "print(f\"{str(len(key_2019_data)).rjust(7)}  -total 2019 data points (train/test)\")\n",
    "print(f\"{str(len(key_2020_data)).rjust(7)}  -total 2020 data points (validate)\")\n",
    "\n",
    "#determine how many cultivars are present in each dataset\n",
    "key_2020_data_cultivars =  key_2020_data['plot_name'].unique()\n",
    "key_2019_data_cultivars = key_2019_data['plot_name'].unique()\n",
    "\n",
    "print(f\"\\n{len(key_2019_data_cultivars)}  -Total CULTIVARS in key_2019_data\")\n",
    "print(f\"{len(key_2020_data_cultivars)}  -Total CULTIVARS in key_2020_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "attended-trouble",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_filename_jpg(row, path):\n",
    "    \n",
    "    #concat the info in the rows\n",
    "    filename = row['dir'] + '_' + row['file'] + '.jpg'\n",
    "\n",
    "    return filename\n",
    "\n",
    "def compare_dir_with_df(dir_filenames_list, df1, df2):\n",
    "       \n",
    "    #collect the relevant columns from the dfs (copy so as to not mess with the originals)\n",
    "    filenames_df1 = df1[['dir', 'file']].copy(deep=True) \n",
    "    filenames_df2 = df2[['dir', 'file']].copy(deep=True) \n",
    "    \n",
    "    #use the helper function create_filename_jpg() as input to a lambda to make new columns \n",
    "    filenames_df1['img_loc'] = filenames_df1.apply (lambda row: create_filename_jpg(row, path), axis=1)\n",
    "    filenames_df2['img_loc'] = filenames_df2.apply (lambda row: create_filename_jpg(row, path), axis=1)\n",
    "    \n",
    "    #put the resultant columns into lists\n",
    "    df1_filenames_list = filenames_df1['img_loc'].tolist()\n",
    "    df2_filenames_list = filenames_df2['img_loc'].tolist()\n",
    "    \n",
    "    #add the two lists together\n",
    "    df_filenames_list = df1_filenames_list + df2_filenames_list\n",
    "    \n",
    "    #report output\n",
    "    print(f\"filenames in dir but not in df: {list(set(df_filenames_list) - set(dir_filenames_list))}\")\n",
    "    print(f\"filenames in df but not in dir: {list(set(dir_filenames_list) - set(df_filenames_list))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "mobile-raise",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#this is failing because of some limit on the number of computations that\n",
    "#jupyter is willing to send to the host server, so we're just going to \n",
    "#assuem that all the files that are supposed to be in the directory are in there\n",
    "#so.... ¯\\_(ツ)_/¯\n",
    "compare_dir_with_df(cropped_filenames_list, key_2020_data, key_2019_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yellow-clinic",
   "metadata": {},
   "source": [
    "### Save the 2020 and 2019 key files as csv's so they persist\n",
    "\n",
    "then create the training and testing sets from the 2019 data! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "armed-parameter",
   "metadata": {},
   "outputs": [],
   "source": [
    "#store to disk\n",
    "key_2019_data.to_csv('/pless_nfs/home/matthewrberning/wheat-awn-classification-multiyear/data/2019_key.csv', index=False)\n",
    "key_2020_data.to_csv('/pless_nfs/home/matthewrberning/wheat-awn-classification-multiyear/data/2020_key.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "nervous-terminology",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read from disk\n",
    "key_2019 = pd.read_csv('/pless_nfs/home/matthewrberning/wheat-awn-classification-multiyear/data/2019_key.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "convertible-physiology",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add a column for the image location\n",
    "#helper function to combine path and appropriate file extention\n",
    "def create_filename(row, path):\n",
    "    \n",
    "    #concat the info in the rows\n",
    "    filename = path + row['dir'] + '_' + row['file'].split('.')[0] + '.jpg'\n",
    "\n",
    "    return filename\n",
    "\n",
    "path = \"/pless_nfs/home/matthewrberning/multi-year-cult-class/data/preprocessed/\"\n",
    "\n",
    "#apply the above helper function with lambda (expect a 'SettingWithCopyWarning')\n",
    "key_2019['img_loc'] = key_2019.apply (lambda row: create_filename(row, path), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "boxed-ticket",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>plot_id</th>\n",
       "      <th>plot_name</th>\n",
       "      <th>yday</th>\n",
       "      <th>date</th>\n",
       "      <th>dir</th>\n",
       "      <th>file</th>\n",
       "      <th>PCTHEAD</th>\n",
       "      <th>AWNS</th>\n",
       "      <th>GRWT</th>\n",
       "      <th>GRYLD</th>\n",
       "      <th>LOI</th>\n",
       "      <th>MOIST</th>\n",
       "      <th>PTHT</th>\n",
       "      <th>SPKLNG</th>\n",
       "      <th>SPLSPK</th>\n",
       "      <th>SPNAREA</th>\n",
       "      <th>TESTWT</th>\n",
       "      <th>TGW</th>\n",
       "      <th>img_loc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19RKY00001</td>\n",
       "      <td>2180</td>\n",
       "      <td>126</td>\n",
       "      <td>2019-05-06</td>\n",
       "      <td>20190506_19RF_AM_X5R_5m_-60_video_Flight1</td>\n",
       "      <td>DJI_A06276_C028_20190506_000063_2800_0824_3311...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/pless_nfs/home/matthewrberning/multi-year-cul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19RKY00001</td>\n",
       "      <td>2180</td>\n",
       "      <td>126</td>\n",
       "      <td>2019-05-06</td>\n",
       "      <td>20190506_19RF_AM_X5R_5m_-60_video_Flight1</td>\n",
       "      <td>DJI_A06276_C028_20190506_000074_0240_0824_0751...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/pless_nfs/home/matthewrberning/multi-year-cul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19RKY00001</td>\n",
       "      <td>2180</td>\n",
       "      <td>126</td>\n",
       "      <td>2019-05-06</td>\n",
       "      <td>20190506_19RF_AM_X5R_5m_-60_video_Flight1</td>\n",
       "      <td>DJI_A06276_C028_20190506_000074_3312_0824_3823...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/pless_nfs/home/matthewrberning/multi-year-cul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19RKY00001</td>\n",
       "      <td>2180</td>\n",
       "      <td>126</td>\n",
       "      <td>2019-05-06</td>\n",
       "      <td>20190506_19RF_AM_X5R_5m_-60_video_Flight1</td>\n",
       "      <td>DJI_A06276_C028_20190506_000068_1776_0824_2287...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/pless_nfs/home/matthewrberning/multi-year-cul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19RKY00001</td>\n",
       "      <td>2180</td>\n",
       "      <td>126</td>\n",
       "      <td>2019-05-06</td>\n",
       "      <td>20190506_19RF_AM_X5R_5m_-60_video_Flight1</td>\n",
       "      <td>DJI_A06276_C028_20190506_000075_1264_0824_1775...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/pless_nfs/home/matthewrberning/multi-year-cul...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      plot_id plot_name  yday        date  \\\n",
       "0  19RKY00001      2180   126  2019-05-06   \n",
       "1  19RKY00001      2180   126  2019-05-06   \n",
       "2  19RKY00001      2180   126  2019-05-06   \n",
       "3  19RKY00001      2180   126  2019-05-06   \n",
       "4  19RKY00001      2180   126  2019-05-06   \n",
       "\n",
       "                                         dir  \\\n",
       "0  20190506_19RF_AM_X5R_5m_-60_video_Flight1   \n",
       "1  20190506_19RF_AM_X5R_5m_-60_video_Flight1   \n",
       "2  20190506_19RF_AM_X5R_5m_-60_video_Flight1   \n",
       "3  20190506_19RF_AM_X5R_5m_-60_video_Flight1   \n",
       "4  20190506_19RF_AM_X5R_5m_-60_video_Flight1   \n",
       "\n",
       "                                                file  PCTHEAD AWNS  GRWT  \\\n",
       "0  DJI_A06276_C028_20190506_000063_2800_0824_3311...     24.0  NaN   NaN   \n",
       "1  DJI_A06276_C028_20190506_000074_0240_0824_0751...     24.0  NaN   NaN   \n",
       "2  DJI_A06276_C028_20190506_000074_3312_0824_3823...     24.0  NaN   NaN   \n",
       "3  DJI_A06276_C028_20190506_000068_1776_0824_2287...     24.0  NaN   NaN   \n",
       "4  DJI_A06276_C028_20190506_000075_1264_0824_1775...     24.0  NaN   NaN   \n",
       "\n",
       "   GRYLD  LOI  MOIST  PTHT  SPKLNG  SPLSPK  SPNAREA  TESTWT  TGW  \\\n",
       "0    NaN  NaN    NaN   NaN     NaN     NaN      NaN     NaN  NaN   \n",
       "1    NaN  NaN    NaN   NaN     NaN     NaN      NaN     NaN  NaN   \n",
       "2    NaN  NaN    NaN   NaN     NaN     NaN      NaN     NaN  NaN   \n",
       "3    NaN  NaN    NaN   NaN     NaN     NaN      NaN     NaN  NaN   \n",
       "4    NaN  NaN    NaN   NaN     NaN     NaN      NaN     NaN  NaN   \n",
       "\n",
       "                                             img_loc  \n",
       "0  /pless_nfs/home/matthewrberning/multi-year-cul...  \n",
       "1  /pless_nfs/home/matthewrberning/multi-year-cul...  \n",
       "2  /pless_nfs/home/matthewrberning/multi-year-cul...  \n",
       "3  /pless_nfs/home/matthewrberning/multi-year-cul...  \n",
       "4  /pless_nfs/home/matthewrberning/multi-year-cul...  "
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_2019.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "developed-johns",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/pless_nfs/home/matthewrberning/multi-year-cult-class/data/preprocessed/20190506_19RF_AM_X5R_5m_-60_video_Flight1_DJI_A06276_C028_20190506_000063_2800_0824_3311_1336_19RKY00001.jpg'"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_2019.iloc(0)[0]['img_loc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "precise-telescope",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 1379769 rows in the 2019 dataset, after removing NaN's 593950 remain...\n"
     ]
    }
   ],
   "source": [
    "#drop all of the rows where there was not yet any data to describe the awn status \n",
    "#i.e. (too early in the season for awns/heads)\n",
    "key_2019_no_nan = key_2019.dropna(subset=['AWNS'])\n",
    "\n",
    "print(f\"there are {len(key_2019)} rows in the 2019 dataset, after removing NaN's {len(key_2019_no_nan)} remain...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "industrial-front",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total cultivars:    338\n",
      "awnless cultivars:   16\n",
      "awned cultivars:    322\n"
     ]
    }
   ],
   "source": [
    "#inspect the awned vs awnless cultivars\n",
    "awned_cultivars = key_2019_no_nan[(key_2019_no_nan['AWNS'] == 'AWNED')]\n",
    "awned_cultivars_set = set(awned_cultivars[\"plot_name\"].to_list()) #setify to get unique values\n",
    "\n",
    "awnless_cultivars = key_2019_no_nan[(key_2019_no_nan['AWNS'] == 'AWNLESS')]\n",
    "awnless_cultivars_set = set(awnless_cultivars[\"plot_name\"].to_list())\n",
    "\n",
    "print(f\"total cultivars:   {str(len(awnless_cultivars_set) + len(awned_cultivars_set)).rjust(4)}\")\n",
    "print(f\"awnless cultivars: {str(len(awnless_cultivars_set)).rjust(4)}\")\n",
    "print(f\"awned cultivars:   {str(len(awned_cultivars_set)).rjust(4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "valuable-symphony",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique awnless plots:  32\n"
     ]
    }
   ],
   "source": [
    "awnless_plots = key_2019_no_nan[(key_2019_no_nan['AWNS'] == 'AWNLESS')]\n",
    "\n",
    "awnless_plots_set = set(awnless_plots[\"plot_id\"].to_list())\n",
    "print(\"unique awnless plots: \",len(awnless_plots_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "wicked-detector",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  257\n",
      "-temp:  65\n",
      "val:    19\n",
      "test:   46\n"
     ]
    }
   ],
   "source": [
    "random.seed(27)\n",
    "\n",
    "awned_cultivars_train = random.sample(awned_cultivars_set, 257)\n",
    "\n",
    "awned_cultivars_val_test_temp = [item for item in awned_cultivars_set if item not in awned_cultivars_train]\n",
    "\n",
    "awned_cultivars_val = random.sample(awned_cultivars_val_test_temp, 19)\n",
    "\n",
    "awned_cultivars_test = [item for item in awned_cultivars_val_test_temp if item not in awned_cultivars_val]\n",
    "\n",
    "print(\"train: \",len(awned_cultivars_train))\n",
    "print(\"-temp: \",len(awned_cultivars_val_test_temp))\n",
    "print(\"val:   \",len(awned_cultivars_val))\n",
    "print(\"test:  \",len(awned_cultivars_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "middle-bullet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cultivar 'OK10119' has 2 plots:\n",
      "['19RKY00709', '19RKY00313']\n",
      "to val: ['19RKY00709']\n",
      "to train: ['19RKY00313']\n",
      "\n",
      "cultivar 'TX03A0148' has 2 plots:\n",
      "['19RKY00330', '19RKY00380']\n",
      "to val: ['19RKY00330']\n",
      "to train: ['19RKY00380']\n",
      "\n",
      "train:  10\n",
      "-val:    2\n",
      "test:   4\n",
      "val plots:  ['19RKY00709', '19RKY00330']\n",
      "train plots:  ['19RKY00313', '19RKY00380']\n",
      "test cultivars:  ['DELIVER', 'PETE', 'ARROW', 'OK1067274']\n"
     ]
    }
   ],
   "source": [
    "#randomly select 12 cultivars to put in the training set \n",
    "#(we're going to hold out 1 of the plots from 2 of the cultivars for the validation set)\n",
    "awnless_cultivars_train = random.sample(awnless_cultivars_set, 12)\n",
    "\n",
    "#put the other 4 cultivars in the test set\n",
    "awnless_cultivars_test = [item for item in awnless_cultivars_set if item not in awnless_cultivars_train]\n",
    "\n",
    "#these will be the two cultivars to segregate out the plots\n",
    "awnless_cultivars_val = random.sample(awnless_cultivars_train, 2)\n",
    "\n",
    "#create a list to hold the plots that I will be putting in the validation set (and also back into the training set)\n",
    "awnless_plots_val_list = []\n",
    "awnless_plots_train_list = []\n",
    "\n",
    "#how many plots from each cultivar will we take?\n",
    "num_plots = 1\n",
    "\n",
    "for cultivar in awnless_cultivars_val:\n",
    "    #remove that cultivar from the list\n",
    "    awnless_cultivars_train.remove(cultivar)\n",
    "    \n",
    "    #collect the plots that correspond to those cultivars\n",
    "    awnless_val_plots_temp_df = key_2019_no_nan[(key_2019_no_nan['plot_name'] == cultivar)]\n",
    "    \n",
    "    awnless_val_plot_ids = set(awnless_val_plots_temp_df[\"plot_id\"].to_list())\n",
    "    \n",
    "    awnless_val_plot_ids_list = list(awnless_val_plot_ids)\n",
    "    \n",
    "    print(f\"cultivar '{cultivar}' has {len(awnless_val_plot_ids_list)} plots:\\n{awnless_val_plot_ids_list}\")\n",
    "    \n",
    "    into_val = random.sample(awnless_val_plot_ids_list, num_plots)\n",
    "    \n",
    "    back_to_train = [item for item in awnless_val_plot_ids_list if item not in into_val]\n",
    "    \n",
    "    print(f\"to val: {into_val}\")\n",
    "    print(f\"to train: {back_to_train}\\n\")\n",
    "          \n",
    "    awnless_plots_val_list.append(into_val[0])\n",
    "    awnless_plots_train_list.append(back_to_train[0])\n",
    "\n",
    "print(\"train: \",len(awnless_cultivars_train))\n",
    "print(\"-val:   \",len(awnless_cultivars_val)) #only used to facilitate segregation\n",
    "print(\"test:  \",len(awnless_cultivars_test))\n",
    "\n",
    "print(\"val plots: \",awnless_plots_val_list)\n",
    "print(\"train plots: \",awnless_plots_train_list)\n",
    "print(\"test cultivars: \", awnless_cultivars_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "destroyed-little",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_2019 = key_2019_no_nan[key_2019_no_nan['plot_id'].isin(awnless_plots_train_list) | key_2019_no_nan['plot_id'].isin(awnless_cultivars_train) | key_2019_no_nan['plot_name'].isin(awned_cultivars_train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "thick-samba",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_set_2019 = key_2019_no_nan[key_2019_no_nan['plot_id'].isin(awnless_plots_val_list) | key_2019_no_nan['plot_name'].isin(awned_cultivars_val)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "musical-highway",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_2019 = key_2019_no_nan[key_2019_no_nan['plot_name'].isin(awnless_cultivars_test) | key_2019_no_nan['plot_name'].isin(awned_cultivars_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "external-article",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train instances:      452466\n",
      "validation instances:  32809\n",
      "test instances:        86863\n"
     ]
    }
   ],
   "source": [
    "print(f\"train instances:      {len(train_set_2019)}\\nvalidation instances:  {len(val_set_2019)}\\ntest instances:        {len(test_set_2019)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "filled-bridal",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-154-9b6f2deefffa>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_set_2019['awn_label'] = train_set_2019[\"AWNS\"].map(awns_dict)\n",
      "<ipython-input-154-9b6f2deefffa>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_set_2019['awn_label'] = test_set_2019[\"AWNS\"].map(awns_dict)\n",
      "<ipython-input-154-9b6f2deefffa>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  val_set_2019['awn_label'] = val_set_2019[\"AWNS\"].map(awns_dict)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['img_loc'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-154-9b6f2deefffa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mval_set_2019\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'awn_label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_set_2019\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"AWNS\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mawns_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_set_2019\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'img_loc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'awn_label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_set_2019\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'img_loc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'awn_label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_set_2019\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'img_loc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'awn_label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/data_exp38/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3028\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3029\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3030\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3032\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/data_exp38/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1264\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1266\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1267\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/data_exp38/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1314\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1316\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['img_loc'] not in index\""
     ]
    }
   ],
   "source": [
    "awns_dict = {\"AWNED\": 0, \"AWNLESS\": 1}\n",
    "\n",
    "train_set_2019['awn_label'] = train_set_2019[\"AWNS\"].map(awns_dict)\n",
    "test_set_2019['awn_label'] = test_set_2019[\"AWNS\"].map(awns_dict)\n",
    "val_set_2019['awn_label'] = val_set_2019[\"AWNS\"].map(awns_dict)\n",
    "\n",
    "train = train_set_2019[['img_loc', 'awn_label']].copy()\n",
    "val = val_set_2019[['img_loc', 'awn_label']].copy()\n",
    "test = test_set_2019[['img_loc', 'awn_label']].copy()\n",
    "\n",
    "train.to_csv('/pless_nfs/home/matthewrberning/wheat-awn-classification-multiyear/data/2019_train_awns.csv', index=False)\n",
    "val.to_csv('/pless_nfs/home/matthewrberning/wheat-awn-classification-multiyear/data/2019_val_awns.csv', index=False)\n",
    "test.to_csv('/pless_nfs/home/matthewrberning/wheat-awn-classification-multiyear/data/2019_test_awns.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mysterious-photography",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
