{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9cb0047",
   "metadata": {},
   "outputs": [],
   "source": [
    "#matthew berning, 2021\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(os.path.dirname('../model/')))\n",
    "sys.path.insert(0, os.path.abspath(os.path.dirname('../data/')))\n",
    "sys.path.insert(0, os.path.abspath(os.path.dirname('../utils/')))\n",
    "\n",
    "from model import Model\n",
    "from dataset import WheatAwnDataset\n",
    "import inspection_functions\n",
    "import tensor_operations\n",
    "import input_validation\n",
    "\n",
    "import PIL\n",
    "import GPUtil\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image as ImDisp\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78396577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 91% |\n",
      "|  1 |  0% |  0% |\n",
      "|  2 |  0% |  0% |\n",
      "|  3 |  0% |  0% |\n"
     ]
    }
   ],
   "source": [
    "GPUtil.showUtilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8fe69f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "most available GPU:  1\n"
     ]
    }
   ],
   "source": [
    "deviceIDs = GPUtil.getAvailable(order = 'first', limit = 1, maxLoad = 0.3, maxMemory = 0.3, includeNan=False, excludeID=[], excludeUUID=[])\n",
    "\n",
    "print(\"most available GPU: \",deviceIDs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "351cff8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assignment\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(deviceIDs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "29253340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_model = Model('vgg16').construct_model(verbose=True)\n",
    "saved_model.load_state_dict(torch.load('/pless_nfs/home/matthewrberning/wheat-awn-classification-multiyear/runs/2021-11-15-23_14_01_model_epoch-6_val-acc-88.676.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "01a90fd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2206d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5140a76c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfc7558",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe0c9aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1e593a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f61c6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae86342",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "saved_model = saved_model.to(device)\n",
    "print(\"device: \",device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236a7e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_csv = '/pless_nfs/home/matthewrberning/wheat-awn-classification-multiyear/data/2019_val_awns_oversampled.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e31b89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2fd818",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a0a38a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e8b13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, os.path.abspath(os.path.dirname('/pless_nfs/home/matthewrberning/wheat-awn-classification-multiyear/model/dataset.py')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3011bd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import WheatAwnDataset\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0d5c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path to images\n",
    "dataset_path = '/pless_nfs/home/matthewrberning/multi-year-cult-class/data/preprocessed/'\n",
    "\n",
    "#compose transforms\n",
    "transforms_ = transforms.Compose([transforms.RandomCrop((224,224)),\n",
    "                                      transforms.ToTensor()])\n",
    "\n",
    "#create the dataset\n",
    "data = WheatAwnDataset(csv_filepath=data_csv, dataset_dir=dataset_path, transform=transforms_)\n",
    "\n",
    "#create the dataloader\n",
    "dataloader = DataLoader(data, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90cb031",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9aace4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dc066f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e6662c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad5246e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4391d6c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b00cc67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92e22a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21f3e52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4951001",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbf3bc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8652411",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b31cc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3eb329",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea79cf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a41bd48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "vgg16 = models.vgg16(pretrained=True)\n",
    "print(vgg16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8173eea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (1): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    " \n",
    "mod = nn.Sequential(*list(vgg16.children())[:-1])\n",
    "print(mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01031b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__() \n",
    "        #img = images\n",
    "        self.fc=nn.Linear(512,2)\n",
    "\n",
    "    \n",
    "    def forward(self,x):     \n",
    "        x=x.view(512,7*7).mean(1).view(1,-1)\n",
    "        x=self.fc(x)\n",
    "        return  F.softmax(x,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "942bf170",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=nn.Sequential(mod,Net())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ac99f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (6): ReLU(inplace=True)\n",
      "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (8): ReLU(inplace=True)\n",
      "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (11): ReLU(inplace=True)\n",
      "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (13): ReLU(inplace=True)\n",
      "      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (15): ReLU(inplace=True)\n",
      "      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (18): ReLU(inplace=True)\n",
      "      (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (20): ReLU(inplace=True)\n",
      "      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (22): ReLU(inplace=True)\n",
      "      (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (25): ReLU(inplace=True)\n",
      "      (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (27): ReLU(inplace=True)\n",
      "      (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (29): ReLU(inplace=True)\n",
      "      (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (1): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  )\n",
      "  (1): Net(\n",
      "    (fc): Linear(in_features=512, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0a18965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.0328,  0.0369, -0.0113,  ..., -0.0035, -0.0055,  0.0205],\n",
       "         [ 0.0095,  0.0140,  0.0183,  ...,  0.0432, -0.0188, -0.0375]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.0105, 0.0289], requires_grad=True)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainable_parameters = []\n",
    "for name, p in model.named_parameters():\n",
    "    if \"fc\" in name:\n",
    "        trainable_parameters.append(p)\n",
    "optimizer = torch.optim.SGD(params=trainable_parameters, lr=0.1, momentum=1e-5)  \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "trainable_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c851396c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.01592763, -0.00082537], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "params = list(Net().parameters())\n",
    "weight = np.squeeze(params[-1].data.numpy())\n",
    "\n",
    "weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "735765d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_CAM(feature_conv, weight, class_idx):\n",
    "    # generate the class -activation maps upsample to 256x256\n",
    "    size_upsample = (256, 256)\n",
    "    bz, nc, h, w = feature_conv.shape\n",
    "    output_cam = []\n",
    "    for idx in class_idx:\n",
    "        beforeDot =  feature_conv.reshape((nc, h*w))\n",
    "        cam = np.matmul(weight[idx], beforeDot)\n",
    "        cam = cam.reshape(h, w)\n",
    "        cam = cam - np.min(cam)\n",
    "        cam_img = cam / np.max(cam)\n",
    "        cam_img = np.uint8(255 * cam_img)\n",
    "        output_cam.append(cv2.resize(cam_img, size_upsample))\n",
    "    return output_cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd434a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ca01a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d68cf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df146274",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388bedcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2cfd95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475ce701",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0671f6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed99ac0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f0698a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9085f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9206406d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c21e022",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67089a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f2608f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59d48c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad04fc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25bd977a",
   "metadata": {},
   "source": [
    "## Grad CAM example\n",
    "from: https://medium.com/@stepanulyanin/implementing-grad-cam-in-pytorch-ea0937c31e82"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "230507ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import copy\n",
    "import os\n",
    "import random\n",
    "\n",
    "#copy a selection of files to work with to a placeholder dir\n",
    "placeholder_dir = \"/pless_nfs/home/matthewrberning/wheat-awn-classification-multiyear/notebooks/cam_imagefolder/\"\n",
    "dataset_dir = \"/pless_nfs/home/matthewrberning/multi-year-cult-class/data/preprocessed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d730429",
   "metadata": {},
   "outputs": [],
   "source": [
    "#collect filenames of images in dataset\n",
    "img_filenames = os.listdir(dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "08d96337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20200603_20ASH_AM_X5R_5m_-90_video_flight1_DJI_A06276_C016_20200603_000509_1264_0824_1775_1336_20ASH00375.jpg\n",
      "20190508_19RF_AM_X5R_5m_-60_video_Flight1_DJI_A06276_C012_20190508_000518_0240_0824_0751_1336_19RKY00430.jpg\n",
      "20190515_19RF_AM_X5R_5m_-60_video_Flight1_DJI_A06276_C005_20190515_000854_1264_0824_1775_1336_19RKY00621.jpg\n",
      "20200515_20ASH_AM_X5R_5m_-60_video_flight2_DJI_A06276_C003_20200515_000817_1776_0824_2287_1336_20ASH00055.jpg\n",
      "20190523_19RF_AM_X5R_5m_-60_video_Flight1_DJI_A00417_C012_20190523_000501_2288_0824_2799_1336_19RKY00431.jpg\n",
      "20200513_20ASH_AM_X5R_5m_-60_video_flight2_DJI_A06276_C016_20200513_000583_2800_0824_3311_1336_20ASH00380.jpg\n",
      "20200609_20ASH_AM_X5R_5m_-60_video_flight1_DJI_A06074_C003_20200609_000259_0240_0824_0751_1336_20ASH00033.jpg\n",
      "20190522_19RF_AM_X5R_5m_-60_video_Flight1_DJI_A00417_C004_20190522_000442_2800_0824_3311_1336_19RKY00637.jpg\n",
      "20190506_19RF_AM_X5R_5m_-60_video_Flight1_DJI_A06276_C014_20190506_000419_0752_0824_1263_1336_19RKY00379.jpg\n",
      "20190610_19RF_AM_X5R_5m_-60_video_Flight1_DJI_A06074_C008_20190610_000938_1264_0824_1775_1336_19RKY00545.jpg\n"
     ]
    }
   ],
   "source": [
    "#choose 10 at random\n",
    "#use shutil.copy() to add files to the placeholder dir\n",
    "#https://docs.python.org/3/library/shutil.html#shutil.copy\n",
    "\n",
    "for i in range(10):\n",
    "    print(img_filenames[random.randint(0,len(img_filenames))])\n",
    "    copy(os.path.abspath(os.path.join(dataset_dir,img_filenames[random.randint(0,len(img_filenames))])), placeholder_dir)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "20641997",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils import data\n",
    "from torchvision.models import vgg19\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# use the ImageNet transformation\n",
    "transform = transforms.Compose([transforms.Resize((224, 224)), \n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "# define a 1 image dataset\n",
    "dataset = datasets.ImageFolder(root=\"/pless_nfs/home/matthewrberning/wheat-awn-classification-multiyear/notebooks/\", transform=transform)\n",
    "\n",
    "# define the dataloader to load that single image\n",
    "dataloader = data.DataLoader(dataset=dataset, shuffle=False, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ac71b743",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d4f6dbb8",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[-1.2445, -1.1418, -1.1932,  ..., -0.4054, -0.6965, -0.7308],\n",
      "          [-1.2445, -1.2617, -1.2617,  ..., -0.4226, -0.7308, -0.6794],\n",
      "          [-1.2103, -1.1932, -1.1247,  ..., -0.3369, -0.7993, -0.8335],\n",
      "          ...,\n",
      "          [-1.6042, -1.6042, -1.6727,  ..., -1.1418, -1.2103, -1.3473],\n",
      "          [-1.0048, -1.0733, -1.1932,  ..., -1.0733, -1.1075, -1.2274],\n",
      "          [-0.6109, -0.6965, -0.7822,  ..., -1.1760, -1.1760, -1.1418]],\n",
      "\n",
      "         [[-0.8627, -0.7577, -0.8102,  ..., -0.0224, -0.3200, -0.3550],\n",
      "          [-0.8627, -0.8803, -0.8978,  ..., -0.0399, -0.3550, -0.3025],\n",
      "          [-0.8627, -0.8277, -0.7577,  ...,  0.0476, -0.4251, -0.4601],\n",
      "          ...,\n",
      "          [-1.2829, -1.2829, -1.3529,  ..., -0.8452, -0.9153, -1.0553],\n",
      "          [-0.6527, -0.7052, -0.8277,  ..., -0.7752, -0.8277, -0.9328],\n",
      "          [-0.2150, -0.3025, -0.3725,  ..., -0.8978, -0.8978, -0.8627]],\n",
      "\n",
      "         [[-1.2641, -1.1596, -1.2119,  ..., -0.5147, -0.7936, -0.8110],\n",
      "          [-1.2467, -1.2641, -1.2641,  ..., -0.5321, -0.8284, -0.7761],\n",
      "          [-1.1770, -1.1596, -1.0724,  ..., -0.4450, -0.9156, -0.9853],\n",
      "          ...,\n",
      "          [-1.5604, -1.5779, -1.6476,  ..., -1.1770, -1.2467, -1.3861],\n",
      "          [-1.0898, -1.1770, -1.2990,  ..., -1.0550, -1.1073, -1.2293],\n",
      "          [-0.8110, -0.9156, -1.0201,  ..., -1.1073, -1.1247, -1.1247]]]]), tensor([1])]\n",
      "[tensor([[[[-1.2788, -1.4158, -1.2959,  ..., -1.6213, -1.5528, -1.5014],\n",
      "          [-1.2959, -1.2959, -1.2959,  ..., -1.4843, -1.4329, -1.3815],\n",
      "          [-1.3815, -1.2617, -1.3302,  ..., -1.5185, -1.4672, -1.4158],\n",
      "          ...,\n",
      "          [-1.2103, -0.6794, -0.4054,  ..., -1.6384, -1.7069, -1.6898],\n",
      "          [-1.2274, -0.7822, -0.5424,  ..., -1.6213, -1.7069, -1.6898],\n",
      "          [-1.2788, -0.8849, -0.6109,  ..., -1.6213, -1.7069, -1.6898]],\n",
      "\n",
      "         [[-0.9678, -1.1078, -0.9853,  ..., -1.3880, -1.3179, -1.2654],\n",
      "          [-1.0028, -1.0028, -1.0028,  ..., -1.2479, -1.1954, -1.1429],\n",
      "          [-1.0903, -0.9678, -1.0378,  ..., -1.2829, -1.2304, -1.1779],\n",
      "          ...,\n",
      "          [-0.8277, -0.2850, -0.0224,  ..., -1.4405, -1.5105, -1.4930],\n",
      "          [-0.8452, -0.3901, -0.1625,  ..., -1.4230, -1.5105, -1.4930],\n",
      "          [-0.8978, -0.4951, -0.2325,  ..., -1.4230, -1.5105, -1.4930]],\n",
      "\n",
      "         [[-1.0898, -1.2293, -1.1073,  ..., -1.3861, -1.3513, -1.2990],\n",
      "          [-1.0898, -1.0898, -1.0898,  ..., -1.2641, -1.2293, -1.1770],\n",
      "          [-1.1596, -1.0376, -1.1073,  ..., -1.2990, -1.2641, -1.2119],\n",
      "          ...,\n",
      "          [-1.2467, -0.7064, -0.3578,  ..., -1.3861, -1.4559, -1.4384],\n",
      "          [-1.2641, -0.7936, -0.4973,  ..., -1.3687, -1.4559, -1.4384],\n",
      "          [-1.3164, -0.8981, -0.5670,  ..., -1.3687, -1.4559, -1.4384]]]]), tensor([1])]\n",
      "[tensor([[[[-0.8335, -0.7822, -0.7650,  ..., -0.3541, -0.2513,  0.1939],\n",
      "          [-0.7308, -0.8678, -0.8335,  ..., -0.1828, -0.1486,  0.0741],\n",
      "          [-0.6452, -0.8164, -0.8678,  ..., -0.1657, -0.1486,  0.0741],\n",
      "          ...,\n",
      "          [ 0.0569,  0.0741, -0.2171,  ..., -0.1143,  0.0741,  0.1768],\n",
      "          [-0.1828,  0.1426,  0.1254,  ..., -0.0458,  0.1426,  0.2453],\n",
      "          [-0.2342,  0.2453,  0.3309,  ..., -0.1143,  0.1426,  0.3652]],\n",
      "\n",
      "         [[-0.4951, -0.4426, -0.4601,  ..., -0.0749,  0.0301,  0.4678],\n",
      "          [-0.3901, -0.5301, -0.5126,  ...,  0.1001,  0.1176,  0.3452],\n",
      "          [-0.3025, -0.4776, -0.5476,  ...,  0.1176,  0.1352,  0.3452],\n",
      "          ...,\n",
      "          [ 0.3277,  0.3277,  0.0476,  ...,  0.2402,  0.4328,  0.5553],\n",
      "          [ 0.0826,  0.4153,  0.3978,  ...,  0.3102,  0.5203,  0.6254],\n",
      "          [ 0.0301,  0.5203,  0.6078,  ...,  0.2402,  0.5203,  0.7479]],\n",
      "\n",
      "         [[-0.7238, -0.6890, -0.7761,  ..., -0.8458, -0.7413, -0.3055],\n",
      "          [-0.6193, -0.7761, -0.8284,  ..., -0.6541, -0.6541, -0.4275],\n",
      "          [-0.5321, -0.7238, -0.8807,  ..., -0.6193, -0.6367, -0.4101],\n",
      "          ...,\n",
      "          [-0.4624, -0.4450, -0.6890,  ..., -0.3404, -0.1661, -0.0964],\n",
      "          [-0.7238, -0.3927, -0.3753,  ..., -0.2707, -0.1138, -0.0267],\n",
      "          [-0.7936, -0.3055, -0.1835,  ..., -0.3753, -0.1138,  0.0779]]]]), tensor([1])]\n",
      "[tensor([[[[ 0.6563,  1.2728,  1.3584,  ...,  1.2899,  0.8447,  0.5022],\n",
      "          [ 0.9132,  1.3070,  1.4098,  ...,  1.2214,  0.8447,  0.5193],\n",
      "          [ 1.1015,  1.3755,  1.5468,  ...,  1.2043,  0.9132,  0.6221],\n",
      "          ...,\n",
      "          [-0.6623, -0.3198, -0.1143,  ...,  0.4851,  0.0227, -0.2513],\n",
      "          [-0.7479, -0.5424, -0.0287,  ...,  0.3652,  0.2111, -0.1828],\n",
      "          [-0.5424, -0.5082,  0.0056,  ...,  0.2453,  0.1426, -0.2856]],\n",
      "\n",
      "         [[ 0.6429,  1.3081,  1.4307,  ...,  1.2906,  0.8704,  0.5378],\n",
      "          [ 0.9055,  1.3256,  1.4832,  ...,  1.2381,  0.8880,  0.5553],\n",
      "          [ 1.0980,  1.3957,  1.6232,  ...,  1.2206,  0.9580,  0.6604],\n",
      "          ...,\n",
      "          [-0.4251, -0.0574,  0.1877,  ...,  0.7304,  0.2927,  0.0476],\n",
      "          [-0.4951, -0.2675,  0.2577,  ...,  0.6429,  0.5028,  0.1352],\n",
      "          [-0.2850, -0.2325,  0.3277,  ...,  0.5203,  0.4503,  0.0476]],\n",
      "\n",
      "         [[-0.1312,  0.5136,  0.6356,  ...,  1.0191,  0.5834,  0.1825],\n",
      "          [ 0.1302,  0.5659,  0.7054,  ...,  0.9494,  0.5659,  0.1999],\n",
      "          [ 0.3393,  0.6531,  0.8622,  ...,  0.9145,  0.6182,  0.3045],\n",
      "          ...,\n",
      "          [-0.9678, -0.7238, -0.6193,  ..., -0.0790, -0.5147, -0.7761],\n",
      "          [-1.0898, -0.9678, -0.5844,  ..., -0.1661, -0.2707, -0.6541],\n",
      "          [-0.8981, -0.9504, -0.5670,  ..., -0.2881, -0.3404, -0.7413]]]]), tensor([1])]\n",
      "[tensor([[[[ 1.5297,  1.7009,  1.6838,  ...,  0.4337,  1.3242,  1.7180],\n",
      "          [ 1.6495,  1.6667,  1.6324,  ...,  0.4851,  1.2899,  1.6495],\n",
      "          [ 1.6838,  1.6324,  1.6153,  ...,  0.4679,  1.2214,  1.5125],\n",
      "          ...,\n",
      "          [-0.8678, -0.9534, -0.8678,  ...,  2.0777,  1.7523,  1.0502],\n",
      "          [-0.8164, -0.9705, -0.8335,  ...,  2.0434,  1.9407,  1.4954],\n",
      "          [-1.0390, -1.0562, -0.6794,  ...,  2.0434,  2.0605,  1.8722]],\n",
      "\n",
      "         [[ 2.0084,  2.1835,  2.1660,  ...,  0.9405,  1.8333,  2.1835],\n",
      "          [ 2.1310,  2.1485,  2.1134,  ...,  0.9930,  1.7808,  2.1134],\n",
      "          [ 2.1660,  2.1134,  2.0959,  ...,  0.9755,  1.7108,  1.9909],\n",
      "          ...,\n",
      "          [-0.4601, -0.5476, -0.4076,  ...,  2.3761,  2.0959,  1.4132],\n",
      "          [-0.4076, -0.5651, -0.3725,  ...,  2.3410,  2.2535,  1.8508],\n",
      "          [-0.6352, -0.6527, -0.2150,  ...,  2.3060,  2.3761,  2.2010]],\n",
      "\n",
      "         [[ 1.8383,  1.9951,  1.9777,  ...,  0.0082,  0.9494,  1.4200],\n",
      "          [ 1.9603,  1.9603,  1.9080,  ...,  0.0605,  0.9319,  1.3677],\n",
      "          [ 1.9951,  1.9254,  1.8731,  ...,  0.0953,  0.9145,  1.2980],\n",
      "          ...,\n",
      "          [-0.8284, -0.9330, -0.8807,  ...,  2.2391,  1.8208,  1.0017],\n",
      "          [-0.7761, -0.9504, -0.8458,  ...,  2.2391,  2.0474,  1.5071],\n",
      "          [-1.0027, -1.0550, -0.6890,  ...,  2.2740,  2.2217,  1.9428]]]]), tensor([1])]\n",
      "[tensor([[[[ 1.5468,  1.4954,  1.1700,  ...,  1.6495,  1.7694,  1.7694],\n",
      "          [ 1.5810,  1.5639,  1.2728,  ...,  0.8789,  1.5297,  1.7523],\n",
      "          [ 1.6153,  1.6324,  1.4269,  ...,  0.6221,  1.4954,  1.6838],\n",
      "          ...,\n",
      "          [ 1.2043,  1.1529,  1.1358,  ..., -1.1760, -1.2445, -1.2617],\n",
      "          [ 1.1187,  1.1358,  1.1700,  ..., -1.1418, -1.1760, -1.2274],\n",
      "          [ 1.1015,  1.1358,  1.2043,  ..., -1.2274, -1.2445, -1.3130]],\n",
      "\n",
      "         [[ 2.0259,  1.9734,  1.6232,  ...,  2.1310,  2.2185,  2.2010],\n",
      "          [ 2.0609,  2.0259,  1.7283,  ...,  1.3431,  1.9909,  2.1835],\n",
      "          [ 2.0959,  2.0959,  1.8859,  ...,  1.1331,  1.9909,  2.1310],\n",
      "          ...,\n",
      "          [ 1.8158,  1.7633,  1.7458,  ..., -0.9853, -1.0553, -1.0553],\n",
      "          [ 1.7283,  1.7458,  1.7808,  ..., -0.9503, -0.9853, -1.0203],\n",
      "          [ 1.7108,  1.7458,  1.8158,  ..., -1.0378, -1.0553, -1.0903]],\n",
      "\n",
      "         [[ 1.8383,  1.8208,  1.5245,  ...,  1.8905,  2.0474,  2.0997],\n",
      "          [ 1.8731,  1.8905,  1.6291,  ...,  1.0714,  1.7685,  2.0125],\n",
      "          [ 1.9080,  1.9603,  1.7860,  ...,  0.7576,  1.6640,  1.8557],\n",
      "          ...,\n",
      "          [ 1.4200,  1.3677,  1.3502,  ..., -1.1770, -1.1247, -1.1073],\n",
      "          [ 1.3328,  1.3502,  1.3851,  ..., -1.1073, -1.0376, -1.0376],\n",
      "          [ 1.3154,  1.3502,  1.4200,  ..., -1.1770, -1.0898, -1.0898]]]]), tensor([1])]\n",
      "[tensor([[[[1.5639, 0.8789, 0.6049,  ..., 1.1015, 0.9988, 0.8618],\n",
      "          [1.5297, 0.8447, 0.6221,  ..., 1.1529, 1.1015, 0.8447],\n",
      "          [1.5468, 0.8961, 0.6392,  ..., 1.1015, 1.1015, 0.7591],\n",
      "          ...,\n",
      "          [2.0434, 2.0777, 2.0434,  ..., 1.8893, 1.8208, 1.6153],\n",
      "          [1.9920, 2.0263, 2.0092,  ..., 1.8893, 1.6495, 1.2214],\n",
      "          [1.9407, 1.9749, 1.9749,  ..., 1.7352, 1.3413, 0.7933]],\n",
      "\n",
      "         [[1.8683, 1.2031, 1.0105,  ..., 1.6933, 1.5707, 1.3957],\n",
      "          [1.8333, 1.1856, 1.0280,  ..., 1.7458, 1.6758, 1.3782],\n",
      "          [1.8508, 1.2381, 1.0455,  ..., 1.6933, 1.6758, 1.2906],\n",
      "          ...,\n",
      "          [2.3410, 2.3761, 2.3410,  ..., 2.3060, 2.2535, 2.0609],\n",
      "          [2.3235, 2.3585, 2.3410,  ..., 2.3235, 2.0959, 1.6758],\n",
      "          [2.2710, 2.3060, 2.3060,  ..., 2.1660, 1.7808, 1.2206]],\n",
      "\n",
      "         [[1.7337, 0.9145, 0.4788,  ..., 1.2282, 1.1062, 0.9319],\n",
      "          [1.6988, 0.8797, 0.4788,  ..., 1.2805, 1.2108, 0.9145],\n",
      "          [1.7163, 0.9319, 0.5136,  ..., 1.2282, 1.2108, 0.8274],\n",
      "          ...,\n",
      "          [2.3088, 2.3437, 2.3088,  ..., 2.2043, 2.0823, 1.8383],\n",
      "          [2.2217, 2.2566, 2.2740,  ..., 2.1868, 1.8905, 1.3851],\n",
      "          [2.1171, 2.1868, 2.2217,  ..., 1.9951, 1.5245, 0.8971]]]]), tensor([1])]\n",
      "[tensor([[[[-1.0048, -1.1418, -1.1589,  ..., -1.1418, -1.1932, -1.3473],\n",
      "          [-0.8335, -1.1075, -1.0733,  ..., -0.9534, -1.0733, -1.1760],\n",
      "          [-0.9192, -0.9705, -1.1075,  ..., -1.0733, -1.1247, -1.1418],\n",
      "          ...,\n",
      "          [-0.1999, -0.4911, -0.8164,  ..., -1.0048, -1.0048, -1.1075],\n",
      "          [-0.4054, -0.6794, -0.9363,  ..., -1.2274, -1.3302, -1.4843],\n",
      "          [-0.4911, -0.6965, -0.8507,  ..., -1.2788, -1.4158, -1.5870]],\n",
      "\n",
      "         [[-0.5651, -0.7052, -0.7227,  ..., -0.7752, -0.8277, -0.9853],\n",
      "          [-0.3901, -0.6702, -0.6352,  ..., -0.5826, -0.7052, -0.8102],\n",
      "          [-0.4776, -0.5301, -0.6702,  ..., -0.7052, -0.7577, -0.7752],\n",
      "          ...,\n",
      "          [ 0.3452,  0.0476, -0.3375,  ..., -0.5126, -0.5476, -0.6702],\n",
      "          [ 0.1176, -0.1625, -0.4776,  ..., -0.7927, -0.9153, -1.0903],\n",
      "          [ 0.0301, -0.2150, -0.4076,  ..., -0.8803, -1.0378, -1.2479]],\n",
      "\n",
      "         [[-0.6890, -0.8284, -0.8458,  ..., -0.8807, -0.9330, -1.1247],\n",
      "          [-0.5321, -0.8284, -0.7761,  ..., -0.6890, -0.8110, -0.9504],\n",
      "          [-0.6367, -0.6890, -0.8284,  ..., -0.8110, -0.8633, -0.8981],\n",
      "          ...,\n",
      "          [ 0.0779, -0.2358, -0.5844,  ..., -0.7238, -0.7587, -0.8633],\n",
      "          [-0.1487, -0.4275, -0.7238,  ..., -0.9678, -1.0550, -1.2293],\n",
      "          [-0.2358, -0.4624, -0.6541,  ..., -1.0027, -1.1421, -1.3339]]]]), tensor([1])]\n",
      "[tensor([[[[-1.4672, -1.3987, -1.3644,  ..., -0.8678, -0.9534, -0.9020],\n",
      "          [-1.1075, -0.9363, -0.9192,  ..., -0.8164, -0.8164, -0.6794],\n",
      "          [-0.7993, -0.7993, -0.7993,  ..., -0.8164, -0.8507, -0.7822],\n",
      "          ...,\n",
      "          [-0.7308, -0.8164, -0.9877,  ..., -0.8678, -0.4568,  0.3309],\n",
      "          [-0.6452, -0.7479, -0.8849,  ..., -0.7137, -0.3712,  0.2796],\n",
      "          [-0.5596, -0.6965, -0.7479,  ..., -0.2513,  0.0398,  0.6221]],\n",
      "\n",
      "         [[-1.2129, -1.1253, -1.0728,  ..., -0.3200, -0.4076, -0.3550],\n",
      "          [-0.8452, -0.6527, -0.6001,  ..., -0.2675, -0.2675, -0.1275],\n",
      "          [-0.5301, -0.5126, -0.4951,  ..., -0.2675, -0.3025, -0.2325],\n",
      "          ...,\n",
      "          [-0.3200, -0.4251, -0.6176,  ..., -0.4426,  0.0651,  0.9405],\n",
      "          [-0.2325, -0.3375, -0.4951,  ..., -0.2500,  0.1527,  0.8880],\n",
      "          [-0.1450, -0.2850, -0.3550,  ...,  0.2227,  0.5903,  1.2381]],\n",
      "\n",
      "         [[-1.5256, -1.4733, -1.4384,  ..., -0.7761, -0.8633, -0.8110],\n",
      "          [-1.1596, -0.9853, -0.9678,  ..., -0.7238, -0.7238, -0.5844],\n",
      "          [-0.8458, -0.8284, -0.8458,  ..., -0.7238, -0.7587, -0.6890],\n",
      "          ...,\n",
      "          [-1.0201, -1.0724, -1.2119,  ..., -1.1073, -0.7761, -0.0267],\n",
      "          [-0.9330, -1.0027, -1.0898,  ..., -0.9853, -0.7413, -0.0964],\n",
      "          [-0.8633, -0.9504, -0.9504,  ..., -0.5495, -0.3578,  0.1999]]]]), tensor([1])]\n",
      "[tensor([[[[-1.4158, -1.5528, -1.6213,  ..., -1.3302, -1.4329, -1.5870],\n",
      "          [-1.3815, -1.4672, -1.4843,  ..., -1.4672, -1.5699, -1.6384],\n",
      "          [-1.5528, -1.5357, -1.4329,  ..., -1.4158, -1.6384, -1.7583],\n",
      "          ...,\n",
      "          [-1.5014, -1.7069, -1.8439,  ..., -0.8507, -0.8507, -0.6109],\n",
      "          [-1.6898, -1.7583, -1.7412,  ..., -0.9705, -0.9705, -0.7308],\n",
      "          [-1.7240, -1.7925, -1.7240,  ..., -0.4397, -0.3883, -0.1828]],\n",
      "\n",
      "         [[-1.3880, -1.5280, -1.6155,  ..., -1.3880, -1.4930, -1.6506],\n",
      "          [-1.3529, -1.4405, -1.4755,  ..., -1.5280, -1.6331, -1.7031],\n",
      "          [-1.5105, -1.4930, -1.3704,  ..., -1.4230, -1.6506, -1.7731],\n",
      "          ...,\n",
      "          [-1.5980, -1.8081, -1.9482,  ..., -0.7402, -0.7052, -0.4426],\n",
      "          [-1.7906, -1.8606, -1.8431,  ..., -0.8277, -0.7927, -0.5476],\n",
      "          [-1.8256, -1.8957, -1.8256,  ..., -0.2500, -0.1625,  0.0476]],\n",
      "\n",
      "         [[-1.3164, -1.4384, -1.4907,  ..., -1.0724, -1.1770, -1.3513],\n",
      "          [-1.2990, -1.3687, -1.3687,  ..., -1.2467, -1.3513, -1.4210],\n",
      "          [-1.4907, -1.4559, -1.3339,  ..., -1.2293, -1.4559, -1.5779],\n",
      "          ...,\n",
      "          [-1.2641, -1.4733, -1.6127,  ..., -0.7587, -0.7936, -0.5670],\n",
      "          [-1.4559, -1.5256, -1.5081,  ..., -0.9504, -0.9853, -0.7413],\n",
      "          [-1.4907, -1.5604, -1.4907,  ..., -0.4798, -0.4798, -0.2707]]]]), tensor([1])]\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(dataiter.next())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afeecbfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f3b6fd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG, self).__init__()\n",
    "        \n",
    "        # get the pretrained VGG19 network\n",
    "        self.vgg = vgg19(pretrained=True)\n",
    "        \n",
    "        # disect the network to access its last convolutional layer\n",
    "        self.features_conv = self.vgg.features[:36]\n",
    "        \n",
    "        # get the max pool of the features stem\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "        \n",
    "        # get the classifier of the vgg19\n",
    "        self.classifier = self.vgg.classifier\n",
    "        \n",
    "        # placeholder for the gradients\n",
    "        self.gradients = None\n",
    "    \n",
    "    # hook for the gradients of the activations\n",
    "    def activations_hook(self, grad):\n",
    "        self.gradients = grad\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features_conv(x)\n",
    "        \n",
    "        # register the hook\n",
    "        h = x.register_hook(self.activations_hook)\n",
    "        \n",
    "        # apply the remaining pooling\n",
    "        x = self.max_pool(x)\n",
    "        x = x.view((1, -1))\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "    # method for the gradient extraction\n",
    "    def get_activations_gradient(self):\n",
    "        return self.gradients\n",
    "    \n",
    "    # method for the activation exctraction\n",
    "    def get_activations(self, x):\n",
    "        return self.features_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1c391dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /pless_nfs/home/matthewrberning/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aafc5461c8d34a72a8ddb600d3e15810",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# initialize the VGG model\n",
    "vgg = VGG()\n",
    "\n",
    "# set the evaluation mode\n",
    "vgg.eval()\n",
    "\n",
    "# get the image from the dataloader\n",
    "img, _ = next(iter(dataloader))\n",
    "\n",
    "# get the most likely prediction of the model\n",
    "pred = vgg(img).argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0b0c92a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = vgg(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "371bf82c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f20766897f0>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get the gradient of the output with respect to the parameters of the model\n",
    "pred[:, 998].backward() #this one is for the ImageNet class called 'ear, spike, capitulum'\n",
    "# pred[:, 386].backward() #this one is for elephants\n",
    "\n",
    "# pull the gradients out of the model\n",
    "gradients = vgg.get_activations_gradient()\n",
    "\n",
    "# pool the gradients across the channels\n",
    "pooled_gradients = torch.mean(gradients, dim=[0, 2, 3])\n",
    "\n",
    "# get the activations of the last convolutional layer\n",
    "activations = vgg.get_activations(img).detach()\n",
    "\n",
    "# weight the channels by corresponding gradients\n",
    "for i in range(512):\n",
    "    activations[:, i, :, :] *= pooled_gradients[i]\n",
    "    \n",
    "# average the channels of the activations\n",
    "heatmap = torch.mean(activations, dim=1).squeeze()\n",
    "\n",
    "# relu on top of the heatmap\n",
    "# expression (2) in https://arxiv.org/pdf/1610.02391.pdf\n",
    "heatmap = np.maximum(heatmap, 0)\n",
    "\n",
    "# normalize the heatmap\n",
    "heatmap /= torch.max(heatmap)\n",
    "\n",
    "# draw the heatmap\n",
    "plt.matshow(heatmap.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc82f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "img = cv2.imread('./data/Elephant/data/05fig34.jpg')\n",
    "heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "heatmap = np.uint8(255 * heatmap)\n",
    "heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "superimposed_img = heatmap * 0.4 + img\n",
    "cv2.imwrite('./map.jpg', superimposed_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67eefde0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4cbbea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5a28f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162dbed0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bff525e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8b77fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c1c90e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9936c0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CAMModel(nn.Module):\n",
    "    def __init__(self, state_dict_path):\n",
    "        super(CAMModel, self).__init__()\n",
    "        \n",
    "        # get the trained network\n",
    "        self.model = models.vgg16(pretrained=False)\n",
    "        \n",
    "        #collect the current set of input features\n",
    "        input_features = self.model.classifier[-1].in_features\n",
    "\n",
    "        #construct our custom classification layer\n",
    "        terminal_layer = nn.Linear(input_features, 2)\n",
    "\n",
    "        #replace the original final linear layer with ours\n",
    "        self.model.classifier[-1] = terminal_layer\n",
    "        \n",
    "        \n",
    "        #load the weights of the trained model\n",
    "        self.model.load_state_dict(torch.load(state_dict_path))\n",
    "        \n",
    "        # disect the network to access its last convolutional layer\n",
    "        self.features_conv = self.model.features[:30]\n",
    "        \n",
    "        #create a maxpooling operation -identical to existing operation\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # get the classifier layers of the vgg16 model\n",
    "        self.classifier = self.model.classifier\n",
    "        \n",
    "        #make a placeholder for the gradients to be collected\n",
    "        self.gradients = None\n",
    "    \n",
    "    # hook for the gradients of the activations\n",
    "    def activations_hook(self, grad):\n",
    "        self.gradients = grad\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features_conv(x)\n",
    "        \n",
    "        # register the hook\n",
    "        h = x.register_hook(self.activations_hook)\n",
    "        \n",
    "        # apply the remaining pooling\n",
    "        x = self.max_pool(x)\n",
    "        x = x.view((1, -1))\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "    # method for the gradient extraction\n",
    "    def get_activations_gradient(self):\n",
    "        return self.gradients\n",
    "    \n",
    "    # method for the activation exctraction\n",
    "    def get_activations(self, x):\n",
    "        return self.features_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ff64f63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cammodel = CAMModel('../runs/2021-12-05-13_42_22_model_epoch-10_val-acc-95.180.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "19e226e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CAMModel(\n",
       "  (model): VGG(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (6): ReLU(inplace=True)\n",
       "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (8): ReLU(inplace=True)\n",
       "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): ReLU(inplace=True)\n",
       "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (13): ReLU(inplace=True)\n",
       "      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (15): ReLU(inplace=True)\n",
       "      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (18): ReLU(inplace=True)\n",
       "      (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (20): ReLU(inplace=True)\n",
       "      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (22): ReLU(inplace=True)\n",
       "      (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (25): ReLU(inplace=True)\n",
       "      (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (27): ReLU(inplace=True)\n",
       "      (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (29): ReLU(inplace=True)\n",
       "      (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "    (classifier): Sequential(\n",
       "      (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "      (4): ReLU(inplace=True)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=4096, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (features_conv): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "  )\n",
       "  (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cammodel.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "84189116",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, _ = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7c9faff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = cammodel(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "17cb23d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.8897,  2.0437]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "cf5710ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "23972d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred[:,1].backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "47eb401c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradients = cammodel.get_activations_gradient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "6cc462bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = cammodel.get_activations(img).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "5b0c6321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f2075a96a30>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAECCAYAAAD+eGJTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAPQ0lEQVR4nO3dW4xd5XnG8eeZk2fGB3zg0GBDDKpLSlECZFIZSGkVE8klCOeiF0SlcpNIVqumIVGkBMRF1LtKiaJESpXIAhKUWOSCkIBQkuICEaItbgZwwWCDOduOT+FkM9ie2TNvL2ZbNSNvj7Xftdce6/v/pNHs0zvvt/eMH6+191rf54gQgHL1dHsAALqLEAAKRwgAhSMEgMIRAkDhCAGgcHMiBGyvtf2C7Zds31pz7wtsP2p7u+3nbN9SZ/8TxtFr+2nbD3ah92Lb99re0Xwdrqq5/1ebr/022/fYHuxwv7tsH7C97YTbltrebHtn8/uSmvt/q/n6P2P7F7YXd6r/TF0PAdu9kv5N0l9LulTS52xfWuMQGpK+FhF/Kmm1pH+quf9xt0ja3oW+kvQ9Sb+JiI9I+lid47C9XNKXJY1ExGWSeiXd1OG2P5a0dsZtt0p6OCJWSXq4eb3O/pslXRYRH5X0oqTbOtj/A7oeApL+XNJLEfFKRIxL+pmkdXU1j4i9EfFU8/JhTf8DWF5Xf0myvULSZyTdUWffZu9Fkq6VdKckRcR4RLxT8zD6JA3Z7pM0LOn3nWwWEY9JemvGzesk3d28fLekz9bZPyIeiohG8+oTklZ0qv9McyEElkvadcL13ar5H+FxtldKukLSlppbf1fS1yVN1dxXki6WdFDSj5q7I3fYnl9X84jYI+nbkt6QtFfSuxHxUF39T3BeROxtjmmvpHO7MIbjviDp13U1mwsh4JPcVvuxzLYXSPq5pK9ExKEa+94g6UBEPFlXzxn6JF0p6QcRcYWkMXV2U/gDmvve6yRdJOl8SfNt31xX/7nG9u2a3kXdVFfPuRACuyVdcML1Ferw5uBMtvs1HQCbIuK+OntLukbSjbZf0/Su0Kds/7TG/rsl7Y6I41s/92o6FOpynaRXI+JgRExIuk/S1TX2P26/7Q9JUvP7gboHYHu9pBsk/W3UeFLPXAiB30laZfsi2wOaflPogbqa27am94e3R8R36up7XETcFhErImKlpp/7IxFR2/+EEbFP0i7blzRvWiPp+br6a3o3YLXt4ebvYo268wbpA5LWNy+vl3R/nc1tr5X0DUk3RsT7dfZWRHT9S9L1mn5H9GVJt9fc+5Oa3v14RtLW5tf1XXod/krSg13oe7mk0eZr8EtJS2ru/y+SdkjaJuknkuZ1uN89mn7/YULTW0JflLRM058K7Gx+X1pz/5c0/d7Y8b/BH9b1+rs5KACFmgu7AwC6iBAACkcIAIUjBIDCEQJA4eZUCNjeQP8y+5f83Lvdf06FgKSu/iLo39X+JT/3rvafayEAoGa1HizUPzA/Bgdbz9UwMTGm/v7WJ7BN9Z/sXKPTF7NEXuPomPoGW/fvO5o7yS986vHP9vx9uLNHk07omPo1r3MNTvH0J+KY+j1L7w7+qZ7Oc4+Fw6kePccmWt43PnlEA71Dp+4/3rp+Nkc1pvE4dtLfQF/bP7UNg4NL9PHVX2q7/v3z+lP9G8O5EFmy/UiqfmqgN1Xf90i3TjSshvtyf27RaMz+oA6aWP3xVP3Qztw5SY3Xd83+oBa2xMMt72N3ACgcIQAULhUC3ZwgFEA12g6BOTBBKIAKZLYEujpBKIBqZEJgzkwQCqB9mRA4rQlCbW+wPWp7dGJiLNEOQCdkQuC0JgiNiI0RMRIRI6c6EAZAd2RCoKsThAKoRtuHcEVEw/aXJP27ppeOuisinqtsZABqkTqOMyJ+JelXFY0FQBdwxCBQOEIAKFytZxFODVjvrRhou36y/VJJ0rElubMIe8faP5VTknoe35qqP9N1+yzALCdPZZ46+GY1A6kYWwJA4QgBoHCEAFA4QgAoHCEAFI4QAApHCACFIwSAwhECQOEIAaBwhABQOEIAKBwhABSOEAAKRwgAhat1PgFPSvPebX9578ZQbj6AwxenyjV+zqmXjp5N/yxLk8/qE5fl6v/n2Vx9l/WtvDBV33jtjVT9e+fnJrQY/ovcAl3DL7S/qrH3tB47WwJA4QgBoHCEAFA4QgAoXGZp8gtsP2p7u+3nbN9S5cAA1CPz6UBD0tci4inbCyU9aXtzRDxf0dgA1KDtLYGI2BsRTzUvH5a0XSxNDpxxKnlPwPZKSVdI2lLFzwNQn/TBQrYXSPq5pK9ExKGT3L9B0gZJGhhanG0HoGKpLQHb/ZoOgE0Rcd/JHhMRGyNiJCJG+uctyLQD0AGZTwcs6U5J2yPiO9UNCUCdMlsC10j6O0mfsr21+XV9ReMCUJO23xOIiMclJc+IAdBtHDEIFI4QAApX63wCshS97ZcvfWJfqv3S/5xM1Tde35Wq71m4MFXvl/ek6ic+eXmqvvdY7vWL3+XmM8jOB5C17KGXU/VvXZeb0GJw73D7xfta/3/PlgBQOEIAKBwhABSOEAAKRwgAhSMEgMIRAkDhCAGgcIQAUDhCACgcIQAUjhAACkcIAIUjBIDCEQJA4WqdT6BnfErzdx9pu77xymup/n1/dF6qPmvq8OGu9u95/K1UfVQ0jjPV5P4Dqfolz52dqvf+xO9votHyLrYEgMIRAkDhCAGgcIQAULh0CNjutf207QerGBCAelWxJXCLppclB3AGyi5IukLSZyTdUc1wANQtuyXwXUlflzSVHwqAbsisSnyDpAMR8eQsj9tge9T26MTEWLvtAHRIdlXiG22/Julnml6d+KczHxQRGyNiJCJG+vvnJ9oB6IS2QyAibouIFRGxUtJNkh6JiJsrGxmAWnCcAFC4Sk4giojfSvptFT8LQL3YEgAKRwgAhat1PgGNHZG25Naoz2js29+13jjz9Z69LFU/ZafqffaS9ovf6W15F1sCQOEIAaBwhABQOEIAKBwhABSOEAAKRwgAhSMEgMIRAkDhCAGgcIQAUDhCACgcIQAUjhAACkcIAIWrdz4BSYrurXLfu2hRqn7y8OHcALr43JE3+Yc3cz8gW3/pn+TqW2BLACgcIQAUjhAACkcIAIXLrkq82Pa9tnfY3m77qqoGBqAe2U8HvifpNxHxN7YHJA1XMCYANWo7BGwvknStpL+XpIgYlzRezbAA1CWzO3CxpIOSfmT7adt32GbZYeAMkwmBPklXSvpBRFwhaUzSrTMfZHuD7VHboxM6lmgHoBMyIbBb0u6I2NK8fq+mQ+EDImJjRIxExEi/5iXaAeiEtkMgIvZJ2mX7kuZNayQ9X8moANQm++nAP0va1Pxk4BVJn88PCUCdUiEQEVsljVQzFADdwBGDQOEIAaBw9c8n0EU+KzefQPzZRan63rHcR6TetT9VP/n226n6rJ7BwVT91NGjqfr0fBKHDqXqsyaff7Ht2ojWf3tsCQCFIwSAwhECQOEIAaBwhABQOEIAKBwhABSOEAAKRwgAhSMEgMIRAkDhCAGgcIQAUDhCACgcIQAUrqj5BBrLl6bq+955PzcAO1V+7IqLU/WDrxxM1ce8gVT91ILcbNPj5+QWuBp+dk+qXl2eT6BT2BIACkcIAIUjBIDCEQJA4VIhYPurtp+zvc32PbZzM0kCqF3bIWB7uaQvSxqJiMsk9Uq6qaqBAahHdnegT9KQ7T5Jw5J+nx8SgDplFiTdI+nbkt6QtFfSuxHxUFUDA1CPzO7AEknrJF0k6XxJ823ffJLHbbA9ant0QrnFNwBUL7M7cJ2kVyPiYERMSLpP0tUzHxQRGyNiJCJG+pU7YgxA9TIh8Iak1baHbVvSGknbqxkWgLpk3hPYIuleSU9Jerb5szZWNC4ANUmdQBQR35T0zYrGAqALOGIQKBwhABTujJpPoGfhwlT9VLJ/9Pem6o+dOz9VP7TzQKp+cl+uPuu9Gy5P1R9amXv9h55upOrVk+vfd+HyXP/GZNul3tff8j62BIDCEQJA4QgBoHCEAFA4QgAoHCEAFI4QAApHCACFIwSAwhECQOEIAaBwhABQOEIAKBwhABSOEAAKV+t8Ah4YUN/yC9uuj6HuzlY8Ndj6nOzTMTmUOx996qzcfATe71z/o0dT9QvufzJXf/lHUvVamHv9epctzvU/kptyv7F7T9u10xOCnxxbAkDhCAGgcIQAUDhCACjcrCFg+y7bB2xvO+G2pbY3297Z/L6ks8ME0CmnsyXwY0lrZ9x2q6SHI2KVpIeb1wGcgWYNgYh4TNJbM25eJ+nu5uW7JX222mEBqEu77wmcFxF7Jan5/dzqhgSgTh0/WMj2BkkbJGmwN7d4CIDqtbslsN/2hySp+b3l0jYRsTEiRiJiZKB3uM12ADql3RB4QNL65uX1ku6vZjgA6nY6HxHeI+m/JV1ie7ftL0r6V0mftr1T0qeb1wGcgWZ9TyAiPtfirjUVjwVAF3DEIFA4QgAoXK3zCai3R1OL2v+EYMc/LEq1X7z8UKo+/mNpqv7YtYdT9f1P5Pr3r84d3X3eo/tT9Xr73VT55Oi22R90CnH5pan6g584K1V/9tb3UvV6NVfeClsCQOEIAaBwhABQOEIAKBwhABSOEAAKRwgAhSMEgMIRAkDhCAGgcIQAUDhCACgcIQAUjhAACkcIAIWrdT6BOHJUU8/saLt+2VNXpfq/NZk7H3w4OVnympUvpuq/f82WVP0fb/rHVP25W+al6scvXJmq7xtbnqr3m7nz+c99bDxVP3HOglS9r/5Y+8Vb/6vlXWwJAIUjBIDCEQJA4dpdmvxbtnfYfsb2L2wv7ugoAXRMu0uTb5Z0WUR8VNKLkm6reFwAatLW0uQR8VBENJpXn5C0ogNjA1CDKt4T+IKkX1fwcwB0Qeo4Adu3S2pI2nSKx/z/0uRiVWJgrmk7BGyvl3SDpDUREa0eFxEbJW2UpEVe2vJxALqjrRCwvVbSNyT9ZUS8X+2QANSp3aXJvy9poaTNtrfa/mGHxwmgQ9pdmvzODowFQBdwxCBQOEIAKBwhABSu1vkEsiIZWat+kvsgo2/XwVT9K7+8IFW/6vNXpuqH3nSqXjtfT5X3/W/u9e9dtjRVH0eOpuqn3s+Nv+eFVHlOHGl5F1sCQOEIAaBwhABQOEIAKBwhABSOEAAKRwgAhSMEgMIRAkDhCAGgcIQAUDhCACgcIQAUjhAACkcIAIXzKWYLr76ZfVDSqU5KP1vSH2oaDv3nVv+Sn3sd/T8cEeec7I5aQ2A2tkcjYoT+5fUv+bl3uz+7A0DhCAGgcHMtBDbSv9j+JT/3rvafU+8JAKjfXNsSAFAzQgAoHCEAFI4QAApHCACF+z875lH59w3MJgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(512):\n",
    "    activations[:, i, :, :] *= pooled_gradients[i]\n",
    "    \n",
    "heatmap = torch.mean(activations, dim=1).squeeze()\n",
    "\n",
    "# relu on top of the heatmap\n",
    "# expression (2) in https://arxiv.org/pdf/1610.02391.pdf\n",
    "heatmap = np.maximum(heatmap, 0)\n",
    "\n",
    "# normalize the heatmap\n",
    "heatmap /= torch.max(heatmap)\n",
    "\n",
    "# draw the heatmap\n",
    "plt.matshow(heatmap.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "241e8b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 224, 224)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f2075a76790>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tensor = img\n",
    "tensor = tensor.squeeze()\n",
    "\n",
    "image = tensor.clone().detach().cpu().numpy()\n",
    "print(image.shape)\n",
    "#re order the dimensionality for matplotlib\n",
    "image = image.transpose(1, 2, 0)\n",
    "\n",
    "image = image.clip(0,1)\n",
    "plt.matshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014e5afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the gradient of the output with respect to the parameters of the model\n",
    "pred[:, 998].backward() #this one is for the ImageNet class called 'ear, spike, capitulum'\n",
    "# pred[:, 386].backward() #this one is for elephants\n",
    "\n",
    "# pull the gradients out of the model\n",
    "gradients = vgg.get_activations_gradient()\n",
    "\n",
    "# pool the gradients across the channels\n",
    "pooled_gradients = torch.mean(gradients, dim=[0, 2, 3])\n",
    "\n",
    "# get the activations of the last convolutional layer\n",
    "activations = vgg.get_activations(img).detach()\n",
    "\n",
    "# weight the channels by corresponding gradients\n",
    "for i in range(512):\n",
    "    activations[:, i, :, :] *= pooled_gradients[i]\n",
    "    \n",
    "# average the channels of the activations\n",
    "heatmap = torch.mean(activations, dim=1).squeeze()\n",
    "\n",
    "# relu on top of the heatmap\n",
    "# expression (2) in https://arxiv.org/pdf/1610.02391.pdf\n",
    "heatmap = np.maximum(heatmap, 0)\n",
    "\n",
    "# normalize the heatmap\n",
    "heatmap /= torch.max(heatmap)\n",
    "\n",
    "# draw the heatmap\n",
    "plt.matshow(heatmap.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0635e0f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14fe9be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bbf740",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1fd836f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.vgg16(pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e1dbfbcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0f3f673a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#collect the current set of input features\n",
    "input_features = model.classifier[-1].in_features\n",
    "\n",
    "#construct our custom classification layer\n",
    "terminal_layer = nn.Linear(input_features, 2)\n",
    "\n",
    "#replace the original final linear layer with ours\n",
    "model.classifier[-1] = terminal_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "642b388d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "12637e31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('../runs/2021-12-05-13_42_22_model_epoch-10_val-acc-95.180.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70df41e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504d4435",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74aba5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5596f3dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c167ce6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0967c39d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0f695644",
   "metadata": {},
   "outputs": [],
   "source": [
    "model9 = models.vgg19(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a2a1c711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (17): ReLU(inplace=True)\n",
      "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (24): ReLU(inplace=True)\n",
      "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (26): ReLU(inplace=True)\n",
      "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (31): ReLU(inplace=True)\n",
      "    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (33): ReLU(inplace=True)\n",
      "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (35): ReLU(inplace=True)\n",
      "    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ece944",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:awnClass38]",
   "language": "python",
   "name": "conda-env-awnClass38-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
